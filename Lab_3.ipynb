{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Algebra and Linear Regression\n",
    "\n",
    "### 13th October 2015 Neil Lawrence\n",
    "\n",
    "\n",
    "## Sum of Squares Error\n",
    "\n",
    "Last week we considered a cost function for minimization of the error. We considered items (films) and users and assumed that each movie rating, $y_{i,j}$ could be summarised by an inner product between a vector associated with the item, $\\mathbf{v}_j$ and one associated with the user $\n",
    "\\mathbf{u}_i$. We justified the inner product as a measure of similarity in the space of 'movie subjects', where both the users and the items lived, giving the analogy of a library.\n",
    "\n",
    "To make predictions we encouraged the similarity to be high if the movie rating was high using the quadratic error function,\n",
    "$$\n",
    "E_{i,j}(\\mathbf{u}_i, \\mathbf{v}_j) = \\left(\\mathbf{u}_i^\\top \\mathbf{v}_j - y_{i,j}\\right)^2,\n",
    "$$\n",
    "which we then summed across all the observations to form the total error\n",
    "$$\n",
    "E(\\mathbf{U}, \\mathbf{V}) = \\sum_{i,j}s_{i,j}\\left(\\mathbf{u}_i^\\top \\mathbf{v}_j - y_{i,j}\\right)^2,\n",
    "$$\n",
    "where $s_{i,j}$ is an indicator variable which is set to 1 if the rating of movie $j$ by user $i$ is provided in our data set. \n",
    "\n",
    "This is known as a sum of squares error. Minimizing it was first proposed by [Legendre](http://en.wikipedia.org/wiki/Adrien-Marie_Legendre) in 1805. His book, which was on the orbit of comets, is available on google books, we can take a look at the relevant page by calling the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe frameborder=\"0\" scrolling=\"yes\" style=\"border:0px\" src=\"http://books.google.co.uk/books?id=spcAAAAAMAAJ&pg=PA72&output=embed\", width=700 height=500></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pods\n",
    "pods.notebook.display_google_book(id='spcAAAAAMAAJ', page=72) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, the main text is in French, but the key part we are interested in can be roughly translated as\n",
    "\n",
    "\"In most matters where we take measures data through observation, the most accurate results they can offer, it is almost always leads to a system of equations of the form\n",
    "$$E = a + bx + cy + fz + etc .$$\n",
    "where a, b, c, f etc are the known coefficients and  x , y, z etc are unknown and must be determined by the condition that the value of E is reduced, for each equation, to an amount or zero or very small.\"\n",
    "\n",
    "He continues\n",
    "\n",
    "\"Of all the principles that we can offer for this item, I think it is not broader, more accurate, nor easier than the one we have used in previous research application, and that is to make the minimum sum of the squares of the errors. By this means, it is between the errors a kind of balance that prevents extreme to prevail, is very specific to make known the state of the closest to the truth system. The sum of the squares of the errors $E^2 + \\left.E^\\prime\\right.^2 + \\left.E^{\\prime\\prime}\\right.^2 + etc$ being\n",
    "\\begin{align*}   &(a + bx + cy + fz + etc)^2 \\\\\n",
    "+ &(a^\\prime + b^\\prime x + c^\\prime y + f^\\prime z + etc ) ^2\\\\\n",
    "+ &(a^{\\prime\\prime} + b^{\\prime\\prime}x  + c^{\\prime\\prime}y +  f^{\\prime\\prime}z + etc )^2 \\\\\n",
    "+ & etc\n",
    "\\end{align*}\n",
    "if we wanted a minimum, by varying x alone, we will have the equation ...\"\n",
    "\n",
    "This is the earliest know printed version of the problem of least squares. The notation, however, is a little awkward for mordern eyes. In particular Legendre doesn't make use of the sum sign,\n",
    "$$\n",
    "\\sum_{i=1}^3 z_i = z_1 + z_2 + z_3\n",
    "$$\n",
    "nor does he make use of the inner product. \n",
    "\n",
    "In our notation, if we were to do linear regression, we would need to subsititue:\n",
    "\\begin{align*}\n",
    "a &\\leftarrow y_1-c, \\\\ a^\\prime &\\leftarrow y_2-c,\\\\ a^{\\prime\\prime} &\\leftarrow y_3 -c,\\\\ \n",
    "\\text{etc.} \n",
    "\\end{align*}\n",
    "to introduce the data observations $\\{y_i\\}_{i=1}^{n}$ alongside $c$, the offset. We would then introduce the input locations\n",
    "\\begin{align*}\n",
    "b & \\leftarrow x_1,\\\\\n",
    "b^\\prime & \\leftarrow x_2,\\\\\n",
    "b^{\\prime\\prime} & \\leftarrow x_3\\\\\n",
    "\\text{etc.}\n",
    "\\end{align*}\n",
    "and finally the gradient of the function\n",
    "$$x \\leftarrow -m.$$\n",
    "The remaining coefficients ($c$ and $f$) would then be zero. That would give us \n",
    "\\begin{align*}   &(y_1 - (mx_1+c))^2 \\\\\n",
    "+ &(y_2 -(mx_2 + c))^2\\\\\n",
    "+ &(y_3 -(mx_3 + c))^2 \\\\\n",
    "+ & \\text{etc.}\n",
    "\\end{align*}\n",
    "which we would write in the modern notation for sums as\n",
    "$$\n",
    "\\sum_{i=1}^n (y_i-(mx_i + c))^2\n",
    "$$\n",
    "which is recognised as the sum of squares error for a linear regression.\n",
    "\n",
    "This shows the advantage of modern [summation operator](http://en.wikipedia.org/wiki/Summation), $\\sum$,  in keeping our mathematical notation compact. Whilst it may look more complicated the first time you see it, understanding the mathematical rules that go around it, allows us to go much further with the notation.\n",
    "\n",
    "Inner products (or [dot products](http://en.wikipedia.org/wiki/Dot_product)) are similar. They allow us to write\n",
    "$$\n",
    "\\sum_{i=1}^q u_i v_i\n",
    "$$\n",
    "in a more compact notation,\n",
    "$\n",
    "\\mathbf{u}\\cdot\\mathbf{v}.\n",
    "$\n",
    "\n",
    "Here we are using bold face to represent vectors, and we assume that the individual elements of a vector $\\mathbf{z}$ are given as a series of scalars\n",
    "$$\n",
    "\\mathbf{z} = \\begin{bmatrix} z_1\\\\ z_2\\\\ \\vdots\\\\ z_n \\end{bmatrix}\n",
    "$$\n",
    "which are each indexed by their position in the vector.\n",
    "\n",
    "## Linear Algebra\n",
    "\n",
    "Linear algebra provides a very similar role, when we introduce [linear algebra](http://en.wikipedia.org/wiki/Linear_algebra), it is because we are faced with a large number of addition and multiplication operations. These operations need to be done together and would be very tedious to write down as a group. So the first reason we reach for linear algebra is for a more compact representation of our mathematical formulae. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Example: Olympic Marathons\n",
    "\n",
    "Now we will load in the Olympic marathon data. This is data of the olympic marath times for the men's marathon from the first olympics in 1896 up until the London 2012 olympics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pods.datasets.olympic_marathon_men()\n",
    "x = data['X']\n",
    "y = data['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see what these values are by typing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1896.]\n",
      " [1900.]\n",
      " [1904.]\n",
      " [1908.]\n",
      " [1912.]\n",
      " [1920.]\n",
      " [1924.]\n",
      " [1928.]\n",
      " [1932.]\n",
      " [1936.]\n",
      " [1948.]\n",
      " [1952.]\n",
      " [1956.]\n",
      " [1960.]\n",
      " [1964.]\n",
      " [1968.]\n",
      " [1972.]\n",
      " [1976.]\n",
      " [1980.]\n",
      " [1984.]\n",
      " [1988.]\n",
      " [1992.]\n",
      " [1996.]\n",
      " [2000.]\n",
      " [2004.]\n",
      " [2008.]\n",
      " [2012.]]\n",
      "[[4.47083333]\n",
      " [4.46472926]\n",
      " [5.22208333]\n",
      " [4.15467867]\n",
      " [3.90331675]\n",
      " [3.56951267]\n",
      " [3.82454477]\n",
      " [3.62483707]\n",
      " [3.59284275]\n",
      " [3.53880792]\n",
      " [3.67010309]\n",
      " [3.39029111]\n",
      " [3.43642612]\n",
      " [3.20583007]\n",
      " [3.13275665]\n",
      " [3.32819844]\n",
      " [3.13583758]\n",
      " [3.0789588 ]\n",
      " [3.10581822]\n",
      " [3.06552909]\n",
      " [3.09357349]\n",
      " [3.16111704]\n",
      " [3.14255244]\n",
      " [3.08527867]\n",
      " [3.10265829]\n",
      " [2.99877553]\n",
      " [3.03392977]]\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that they are not `pandas` data frames for this example, they are just arrays of dimensionality $n\\times 1$, where $n$ is the number of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this lab is to have you coding linear regression in python. We will do it in two ways, once using iterative updates (coordinate ascent) and then using linear algebra. The linear algebra approach will not only work much better, it is easy to extend to multiple input linear regression and *non-linear* regression using basis functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Data\n",
    "\n",
    "You can make a plot of $y$ vs $x$ with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'pace in min/km')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAGNtJREFUeJzt3X+UZGV95/H3N4CAIEFhdJEfO3hi3BADRnoAV9bY6BJQDuhBZ92sAcQscTYJ7CZmlM32RGZOssusZ/Xk1xhUzoG4xowYViRGRGnWowHsHn4MTEAZFIFAwvAjCLqCP777x711p6anf9zq6Vu3qvr9OqdO1X3q6arnds3Up5/nufe5kZlIkgTwU203QJI0OAwFSVLFUJAkVQwFSVLFUJAkVQwFSVLFUJAkVQwFSVLFUJAkVfZuuwG9OvTQQ3PlypVtN0OShsqWLVsey8wVC9UbulBYuXIl09PTbTdDkoZKRHynTj2HjyRJFUNBklQxFCRJFUNBklQxFCRJFUNhMTZuhMnJXcsmJ4tySRpihsJirFoFq1fvDIbJyWJ71ap22yVJe2jozlMYCOPjsHlzEQRr1sCmTcX2+HjbLZOkPWJPYbHGx4tA2LChuDcQJI0AQ2GxJieLHsLERHE/c45BkoaQobAYnTmEzZth/fqdQ0kGg6QhZygsxtTUrnMInTmGqal22yVJeygys+029GRsbCxdEE+SehMRWzJzbKF69hQkSRVDQZJUMRQkSRVDQZJUMRQkSRVDQZJUMRQkSRVDQZJUMRQkSRVDQZJUMRQkSZVGQyEi7o+IOyPi9ojYbcGiKPxRRGyPiK0R8eom2yNJml8/rrw2npmPzfHc6cDLy9uJwKbyXpLUgraHj84CrszCzcDBEXFYy22SpGWr6VBI4IsRsSUiLpjl+cOBB7u2HyrLJEktaHr46LWZ+XBEvBi4PiLuycyvdD0fs/zMbhd4KAPlAoCjjjqqmZZKkprtKWTmw+X9o8DVwAkzqjwEHNm1fQTw8Cyvc1lmjmXm2IoVK5pqriQte42FQkQcEBEv6DwGTgXumlHtGuCc8iikk4CnMvORptokSZpfk8NHLwGujojO+3wyM78QEe8ByMyPAJ8H3gRsB74PvKvB9kiSFtBYKGTmt4DjZin/SNfjBH6jqTZIknrT9iGpkqQBYihIkiqGgiSpYihIkiqGgiSpYihIkiqGgiSpYihIkiqGgiSpYihIkiqGgiSpYihIkiqGgiSpYihIkiqGgiSpYihIkiqGgiSpYihIkiqGgiSpYihIkiqGgiSpYihIkiqGgiSpYihIkiqGgiSpYihIkiqGgiSpYihIkiqGgiSpYihIkiqGgiSpYihIkiqGgiSpYihIkiqGgiSpYihIkiqNh0JE7BURt0XEtbM8d15E7IiI28vbrzXdHknS3PauUykijgVWdtfPzL+u+R4XAXcDB83x/F9l5m/WfC1JUoMWDIWIuBw4FtgG/KQsTmDBUIiII4A3A38A/PbimylJ6oc6PYWTMvOYRb7+h4G1wAvmqXN2RLwO+CbwXzLzwZkVIuIC4AKAo446qrcWbNwIq1bB+PjOsslJmJqCtWt7ey1JGnF15hRuioieQyEizgAezcwt81T7HLAyM48FvgRcMVulzLwsM8cyc2zFihW9NWTVKli9uggCKO5Xry7KZ9q4cWe9jsnJolySloE6oXAFRTB8IyK2RsSdEbG1xs+9FjgzIu4HPgWcEhGf6K6QmY9n5rPl5keB43toez3j47B5cxEE69YV95s379pz6OglQCRpBNUZProc+FXgTnbOKSwoMy8GLgaIiNcD783Md3bXiYjDMvORcvNMignppTc+DmvWwIYNMDExeyB06nUCZM0a2LRp7gCRpBFUJxQeyMxrluoNI2I9MF2+5oURcSbwI+AJ4Lylep9dTE4WX/ATE8X9+Pj8wVAnQCRpBEVmzl8h4s+AgynG/ztDPb0ckrqkxsbGcnp6uv4PdIaAOn/xz9yeq749BUkjJCK2ZObYQvXq9BT2pwiDU7vKah2SOhCmpnb9Yu8MEU1N7f5lPzMwxsfnDxBJGjF1egovyswnZpQdnZnfbrRlc+i5p9ALD1+VNKLq9hTqhMLXgNMz87vl9s8Bn87MVy5JS3vUaChI0oiqGwp1Dkn9Q+BzEXFgRBwPXAW8c4GfkSQNoQXnFDLzbyJiH+CLFGcmvyUz7228ZZKkvpszFCLijykmlDsOAr4F/FZEkJkXNt04SVJ/zddTmDlwP99yFZKkETBfKLwW+FvgS5n5dJ/aI0lq0XwTzZcDxwGfj4gvR8T7IuK4PrVLktSCOXsKmXkzcDPwgYg4hOLktd8pL7hzK/CFzNzcn2ZKkvqh1pXXMvNx4C/LG+Whqac12C5JUgvqXHltX+Bsdr8c5/rmmiVJakOdnsJngacojj56doG6kqQhVicUjshMh4okaRmos8zF30XELzTeEklS6+r0FE4GzouIb1MMHwWQ5XWVJUkjpE4onN54KyRJA2G+tY8OKpfL9mxmSVom5uspfBI4g+Koo6QYNupI4GUNtkuS1IL5zmg+o7w/un/NkSS1qdYZzeXSFivZ9eS14bhGsySptjpnNF8OHAtsA35SFidgKEjSiKnTUzgpM49pvCWjauNGWLUKxsd3lk1OwtQUrF3bXrskaRZ1Tl67KSIMhcVatQpWry6CAIr71auLckkaMHV6CldQBMM/4slrvRsfh82biyBYswY2bSq2u3sOkjQg6oTC5cCvAneyc05BvRgfLwJhwwaYmDAQJA2sOqHwQGZe03hLRtnkZNFDmJgo7sfHDQZJA6lOKNwTEZ8EPkfX0tkeklpTZw6hM2Q0Pr7rtiQNkDqhsD9FGJzaVeYhqXVNTe0aAJ05hqkpQ0HSwInMbLsNPRkbG8vp6em2myFJQyUitmTm2EL16hySKklaJgwFSVLFUJAkVeqsfbQvcDa7L4i3vrlmSZLaUOfoo88CT1FcV+HZBepKkoZYnVA4IjNPW+wbRMRewDTwD51rNHQ9ty9wJXA88Djw7zLz/sW+lyRpz9SZU/i7iPiFPXiPi4C753ju3cCTmfkzwIeAS/fgfSRJe6hOKJwMbImIb0TE1oi4MyK21nnxiDgCeDPwsTmqnEWx4B7AVcAbIiLmqCtJalid4aPT9+D1PwysBV4wx/OHAw8CZOaPIuIp4BDgsT14T0nSIs3ZU4iIg8qHT89xm1dEnAE8mplb5qs2S9lup1hHxAURMR0R0zt27FjorSVJizRfT+GTwBkURx0lu36BJ/CyBV77tcCZEfEmYD/goIj4RGa+s6vOQ8CRwEMRsTfw08ATM18oMy8DLoNimYsF3leStEhzhkLnSKHMPHoxL5yZFwMXA0TE64H3zggEgGuAc4GbgLcBN+SwLcYkSSOkzpzCkoqI9cB0eY2GjwN/ERHbKXoI7+h3eyRJO/UlFDLzRuDG8vG6rvIfAG/vRxskSQtz7aNBsXFjcUGebpOTRbkk9UmtUIiIkyPiXeXjFRGxqHkGzWPVquKKbJ1g6FyxbdWqdtslaVlZMBQi4veB91FOGgP7AJ9oslHLUueKbKtXw7p1XrJTUivq9BTeCpwJfA8gMx9m7pPRtCfGx2HNGtiwobg3ECT1WZ1QeK48TDQBIuKAZpu0jE1OwqZNMDFR3M+cY5CkhtUJhc0R8efAwRHxH4EvAR9ttlnLUGcOYfNmWL9+51CSwSCpjxYMhcz8IMVidZ8BXgGsy8w/brphy87U1K5zCJ05hqmpdtslaVmJhU4gLo80eqQ8p4CI2B94SVvXPRgbG8vp6ek23nq0bdxYHOnUPY8xOVmE0tq17bVL0pKIiC2ZObZQvTrDR58GftK1/eOyTKPEQ2IlUe+M5r0z87nORmY+FxHPa7BNakP3IbFr1hQT3R4SKy07dXoKOyLizM5GRJyF1zsYTR4SKy17dULhPcB/jYgHIuJBihPZfr3ZZqkVHhIrLXsLDh9l5n3ASRFxIMXE9IIX2NEQ6j4kdny8uHlWtbTs1FolNSLeDPw8sF/nEsqZub7Bdqnf5jsk1lCQlo0FQyEiPgI8HxgHPkZxMZyvN9wu9dtsh512egySlo06cwr/OjPPAZ7MzEuA11BcQlOSNGLqhML/K++/HxEvBX4IuHS2JI2gOnMK10bEwcD/BG6lWBjPtY8kaQTVOfpoQ/nwMxFxLbBfZj7VbLMkSW2oM9G8H/CfgJMpeglfjYhNnbWQJEmjo87w0ZXA00BnZdR/D/wF8PamGiVJakedUHhFZh7XtT0ZEXc01SCp71whVqrUOfrotog4qbMREScCX2uuSVKfuUKsVKnTUzgROCciHii3jwLujog7gczMYxtrndQPrhArVeqEwmmNt0JqW/cKsRMTBoKWrTqX4/zOfLd+NFIDZOPG3VdPnZwsyoeZK8RKQL05BWmnURx/714hdv36nUNJBoOWIUNBvekef1+3bjSW155vhVhpmYnMbLsNPRkbG8vp6em2m6F163aOv6+fYxV1D/WUBkZEbMnMsYXq2VNQ7+qOv4/iUJM04gyFUdbEpHAv4++jONQkjThDYZQ18Zd6r+Pv3Yd6rlljIEgDzjmFUdcJgrZOymr7/SUBzimoo82/1OsONY3quQ/SEDIURl2bJ2XVHWpyQloaGA4fjbLuv9THx3ffHiQOM0mNan34KCL2i4ivR8QdEbEtIi6Zpc55EbEjIm4vb7/WVHuWpWE6KcsJaWkgNNZTiIgADsjMZyJiH+CrwEWZeXNXnfOAscz8zbqva09hRNlTkBrVek8hC8+Um/uUt+Eaq1J/uPaQNDAanWiOiL0i4nbgUeD6zLxllmpnR8TWiLgqIo6c43UuiIjpiJjesWNHk01WG4ZpmEsacX2ZaI6Ig4Grgd/KzLu6yg8BnsnMZyPiPcDqzDxlvtdy+EiSetf68FG3zPxn4EZmXLAnMx/PzGfLzY8Cx/ejPZKk2TV59NGKsodAROwPvBG4Z0adw7o2zwTubqo9Ul95Qp6GVJM9hcOAyYjYCkxRzClcGxHrI+LMss6F5eGqdwAXAuc12B6pfzwhT0PKk9ekpniYrQbIQM0pSMuSJ+RpCBkKUl29zhO0ue6UtEiGglRXL/MEnpCnIWUoSHX1ciU5T8jTkHKiWerVunXFPMHERNELkIaAE81SE5wn0IgzFKS6nCfQMmAoSHUNyzyBZ1NrDxgKUl1r1+4+qTw+XpQPEs+m1h7Yu+0GSFpi3UdJeTa1emRPQRpFnk2tRTIUpFHkUVJaJENBGjUeJaU9YChIo2ZYjpLSQPKMZklaBjyjWZLUM0NBklQxFCRJFUNBapNLUmjAGApSm1ySQgPGZS6kNrkkhQaMPQWpbS5JsXQcjttjhoLUNpekWDoOx+0xQ0Fqk0tSLK1erqNtr2JWhoLUpl6WpGjiS2wUvxjrDsfZq5hdZg7V7fjjj09pWbrhhsxDDy3uZ9selNdsW2cfJiYW3pde6g45YDprfMe2/iXf681Q0LLWxJfYUr/mpZfu/ho33FCUN20xITcxUXwVTkw0374W1Q0Fh4+kYdLEkUpL/ZpNDMvUHebqdYXYpZ7kH4XhuDrJMUg3ewpa1oahp9DEa7Y5dNZLz2eAh+Nw+EgaMcPyxdix1MMybQ1z9fp7H9B5CkNBGjVNjNW3+cU4CEFTV69f9AM4T2EoSFpadb8Y6wbIsP0FXveLvu12zsFQkLT06nwxLmYMfqmCpinD0s55GAqSllZTfwEvddAstV6+6Nsc4luAoSBp6TT1F/CADrXsos1A6rzXEvzuWw8FYD/g68AdwDbgklnq7Av8FbAduAVYudDrGgpSC5r4YhzgoZaBswThWTcUmjx57VnglMw8DngVcFpEnDSjzruBJzPzZ4APAZc22B5Ji7V27e4ntY2PF+WL1euJZqOk15Pc+ri8emOhUIbTM+XmPuUtZ1Q7C7iifHwV8IaIiKbaJGmANBE0w6LXs777uLx6o8tcRMReEXE78ChwfWbeMqPK4cCDAJn5I+Ap4JAm2yRJretlie8+L6/eaChk5o8z81XAEcAJEfHKGVVm6xXM7E0QERdExHRETO/YsaOJpkpSf9UdEurzMFsU8w/Ni4jfB76XmR/sKrsO+EBm3hQRewP/CKzIeRo1NjaW09PTzTdYkprU6QH06drcEbElM8cWqtdYTyEiVkTEweXj/YE3AvfMqHYNcG75+G3ADfMFgiSNhAG+4l6Tw0eHAZMRsRWYophTuDYi1kfEmWWdjwOHRMR24LeB9zfYHkkaDAN85FXfho+WisNHktS71oePJEnDx1CQJFUMBUlSxVCQJFUMBUlSZeiOPoqIHcB3+vBWhwKP9eF9+mXU9gdGb59GbX9g9PZpmPfnX2bmioUqDV0o9EtETNc5fGtYjNr+wOjt06jtD4zePo3a/szG4SNJUsVQkCRVDIW5XdZ2A5bYqO0PjN4+jdr+wOjt06jtz26cU5AkVewpSJIqyyYUIuLyiHg0Iu7qKjsuIm6KiDsj4nMRcVDXcxdHxPaI+EZE/HJX+Wll2faIaHVV1172KSL+bURsKcu3RMQpXT9zfFm+PSL+qK1Lovb6GZXPHxURz0TEe7vKhvIzKp87tnxuW/n8fmX50H1GEbFPRFxRlt8dERd3/cxAfEYRcWRETJbt2xYRF5XlL4qI6yPi3vL+hWV5lL//7RGxNSJe3fVa55b1742Ic+d6z4GXmcviBrwOeDVwV1fZFPBL5ePzgQ3l42OAO4B9gaOB+4C9ytt9wMuA55V1jhmSffpF4KXl41cC/9D1M18HXkNxJby/BU4f9P3pev4zwKeB95bbw/wZ7Q1sBY4rtw8B9hrWzwj4FeBT5ePnA/cDKwfpM6JY4v/V5eMXAN8s//9vBN5flr8fuLR8/Kby9x/AScAtZfmLgG+V9y8sH7+wrX93e3JbNj2FzPwK8MSM4lcAXykfXw+cXT4+i+If87OZ+W1gO3BCeduemd/KzOeAT5V1W9HLPmXmbZn5cFm+DdgvIvaNiMOAgzLzpiz+dV8JvKX51u+ux8+IiHgLxX++bV31h/YzAk4FtmbmHeXPPp6ZPx7izyiBA6K4quL+wHPAdxmgzygzH8nMW8vHTwN3U1w7/izgirLaFez8fZ8FXJmFm4GDy8/nlymuGfNEZj5J8Xs4rY+7smSWTSjM4S6gc8GftwNHlo8PBx7sqvdQWTZX+SCZa5+6nQ3clpnPUrT/oa7nBm2fZt2fiDgAeB9wyYz6w/wZ/SyQEXFdRNwaEWvL8qH8jICrgO8BjwAPAB/MzCcY0M8oIlZS9KhvAV6SmY9AERzAi8tqw/zdUMtyD4Xzgd+IiC0UXcfnyvLZxmtznvJBMtc+ARARPw9cCvx6p2iW1xikfZprfy4BPpSZz8yoP+j7A3Pv097AycB/KO/fGhFvYPD3aa79OQH4MfBSimHY34mIlzGA+xMRB1IMRf7nzPzufFVnKRuW74Za9m67AW3KzHsouuxExM8Cby6feohd/8I+AugMvcxVPhDm2Sci4gjgauCczLyvLH6IYj86Bmqf5tmfE4G3RcRG4GDgJxHxA2ALw/sZPQT838x8rHzu8xTj959gOD+jXwG+kJk/BB6NiK8BYxR/UQ/MZxQR+1AEwv/OzL8ui/8pIg7LzEfK4aFHy/K5vhseAl4/o/zGJtvdlGXdU4iIF5f3PwX8N+Aj5VPXAO8ox9yPBl5OMdE3Bbw8Io6OiOcB7yjrDoy59ikiDgb+Brg4M7/WqV92jZ+OiJPKI1rOAT7b94bPYa79ycx/k5krM3Ml8GHgDzPzTxjizwi4Djg2Ip5fjsP/EvD3w/oZUQwZnVIesXMAxcTsPQzQZ1T+Pj8O3J2Z/6vrqWuAzhFE57Lz930NcE65TycBT5Wfz3XAqRHxwvJIpVPLsuHT9kx3v27AX1KMbf6QItXfDVxEcbTBN4H/QXkyX1n/9yiOkPgGXUd6UBx98M3yud8bln2i+M/6PeD2rtuLy+fGKMaF7wP+pPv3MKj7M+PnPkB59NEwf0Zl/XdSTJzfBWzsKh+6zwg4kOLIsG3A3wO/O2ifEcUwXVIc9dX5f/EmiiO/vgzcW96/qKwfwJ+W7b4TGOt6rfMpDkrZDryrzX93e3LzjGZJUmVZDx9JknZlKEiSKoaCJKliKEiSKoaCJKliKEiSKoaC1IKI2KvtNkizMRSkBUTEhs46++X2H0TEhRHxuxExVa6rf0nX8/8nimtWbIuIC7rKn4mI9RFxC8Uy2NLAMRSkhX2ccsmDcimHdwD/RLH8yQnAq4DjI+J1Zf3zM/N4irOQL4yIQ8ryAyiuQ3BiZn61nzsg1bWsF8ST6sjM+yPi8Yj4ReAlwG3AKor1bW4rqx1IERJfoQiCt5blR5blj1OsGPqZfrZd6pWhINXzMeA84F8AlwNvAP57Zv55d6WIeD3wRuA1mfn9iLgR2K98+geZ+eN+NVhaDIePpHqupriS1iqK1S+vA84v1+EnIg4vVwv9aeDJMhD+FcXKoNLQsKcg1ZCZz0XEJPDP5V/7X4yInwNuKlZf5hmKFU6/ALwnIrZSrLB7c1ttlhbDVVKlGsoJ5luBt2fmvW23R2qKw0fSAiLiGIo18r9sIGjU2VOQJFXsKUiSKoaCJKliKEiSKoaCJKliKEiSKoaCJKny/wGolhfZvHB+YwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import pylab as plt\n",
    "\n",
    "plt.plot(x, y, 'rx')\n",
    "plt.xlabel('year')\n",
    "plt.ylabel('pace in min/km')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Likelihood: Iterative Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will take the maximum likelihood approach we derived in the lecture to fit a line, $y_i=mx_i + c$, to the data you've plotted. We are trying to minimize the error function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$E(m, c) =  \\sum_{i=1}^n(y_i-mx_i-c)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with respect to $m$, $c$ and $\\sigma^2$. We can start with an initial guess for $m$, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = -0.4\n",
    "c = 80 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the maximum likelihood update to find an estimate for the offset, $c$.\n",
    "\n",
    "### Coordinate Descent\n",
    "\n",
    "In the movie recommender system example, we minimised the objective function by steepest descent based gradient methods. Our updates required us to compute the gradient at the position we were located, then to update the gradient according to the direction of steepest descent. This time, we will take another approach. It is known as *coordinate descent*. In coordinate descent, we choose to move one parameter at a time. Ideally, we design an algorithm that at each step moves the parameter to its minimum value. At each step we choose to move the individual parameter to its minimum.\n",
    "\n",
    "To find the minimum, we look for the point in the curve where the gradient is zero. This can be found by taking the gradient of $E(m,c)$ with respect to the parameter. \n",
    "\n",
    "#### Update for Offset\n",
    "\n",
    "Let's consider the parameter $c$ first. The gradient goes nicely through the summation operator, and we obtain\n",
    "$$\n",
    "\\frac{\\text{d}E(m,c)}{\\text{d}c} = -\\sum_{i=1}^n 2(y_i-mx_i-c).\n",
    "$$\n",
    "Now we want the point that is a minimum. A minimum is an example of a [*stationary point*](http://en.wikipedia.org/wiki/Stationary_point), the stationary points are those points of the function where the gradient is zero. They are found by solving the equation for $\\frac{\\text{d}E(m,c)}{\\text{d}c} = 0$. Substituting in to our gradient, we can obtain the following equation, \n",
    "$$\n",
    "0 = -\\sum_{i=1}^n 2(y_i-mx_i-c)\n",
    "$$\n",
    "which can be reorganised as follows,\n",
    "$$\n",
    "c^* = \\frac{\\sum_{i=1}^n(y_i-m^*x_i)}{n}.\n",
    "$$\n",
    "The fact that the stationary point is easily extracted in this manner implies that the solution is *unique*. There is only one stationary point for this system. Traditionally when trying to determine the type of stationary point we have encountered we now compute the *second derivative*,\n",
    "$$\n",
    "\\frac{\\text{d}^2E(m,c)}{\\text{d}c^2} = 2n.\n",
    "$$\n",
    "The second derivative is positive, which in turn implies that we have found a minimum of the function. This means that setting $c$ in this way will take us to the lowest point along that axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "786.0197711453593\n"
     ]
    }
   ],
   "source": [
    "# set c to the minimum\n",
    "c = (y - m*x).mean()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update for Slope\n",
    "\n",
    "Now we have the offset set to the minimum value, in coordinate descent, the next step is to optimise another parameter. Only one further parameter remains. That is the slope of the system. \n",
    "\n",
    "Now we can turn our attention to the slope. We once again peform the same set of computations to find the minima. We end up with an update equation of the following form.\n",
    "\n",
    "$$m^* = \\frac{\\sum_{i=1}^n (y_i - c)x_i}{\\sum_{i=1}^n x_i^2}$$\n",
    "\n",
    "Communication of mathematics in data science is an essential skill, in a moment, you will be asked to rederive the equation above. Before we do that, however, we will briefly review how to write mathematics in the notebook.\n",
    "\n",
    "### $\\LaTeX$ for Maths\n",
    "\n",
    "These cells use [Markdown format](http://en.wikipedia.org/wiki/Markdown). You can include maths in your markdown using [$\\LaTeX$ syntax](http://en.wikipedia.org/wiki/LaTeX), all you have to do is write your answer inside dollar signs, as follows:\n",
    "\n",
    "To write a fraction, we write `$\\frac{a}{b}$`, and it will display like this $\\frac{a}{b}$. To write a subscript we write `$a_b$` which will appear as $a_b$. To write a superscript (for example in a polynomial) we write `$a^b$` which will appear as $a^b$. There are lots of other macros as well, for example we can do greek letters such as `$\\alpha, \\beta, \\gamma$` rendering as $\\alpha, \\beta, \\gamma$. And we can do sum and intergral signs as `$\\sum \\int \\int$`.\n",
    "\n",
    "You can combine many of these operations together for composing expressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Question 1 \n",
    "\n",
    "Convert the following python code expressions into $\\LaTeX$j, writing your answers below. In each case write your answer as a single equality (i.e. your maths should only contain one expression, not several lines of expressions). For the purposes of your $\\LaTeX$ please assume that `x` and `w` are $n$ dimensional vectors. \n",
    "\n",
    "(a) f = x.sum()\n",
    "\n",
    "\n",
    "(b) m = x.mean()\n",
    "\n",
    "\n",
    "(c) g = (x*w).sum()\n",
    "\n",
    "\n",
    "*15 marks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1 Answer\n",
    "\n",
    "Write your answer to the question in this box.\n",
    "\n",
    "(a)$${f} = \\sum_{i=1}^n x_i$$\n",
    "\n",
    "(b)$$m^* = \\frac{\\sum_{i=1}^n x_i}{n}$$\n",
    "\n",
    "(c)$${g} = \\sum_{i=1}^n x_iw_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient With Respect to the Slope\n",
    "Now that you've had a little training in writing maths with $\\LaTeX$, we will be able to use it to answer questions. The next thing we are going to do is a little differentiation practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Question 2\n",
    "\n",
    "Derive the the gradient of the objective function with respect to the slope, $m$. Rearrange it to show that the update equation written above does find the stationary points of the objective function. By computing its derivative show that it's a minimum.\n",
    "\n",
    "*20 marks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2 Answer\n",
    "\n",
    "Write your answer to the question in this box.\n",
    "\n",
    "$$E(m, c) =  \\sum_{i=1}^n(y_i-mx_i-c)^2$$\n",
    "\n",
    "Differentiating above equation with respect to m.\n",
    "\n",
    "$$\n",
    "\\frac{\\text{d}E(m,c)}{\\text{d}m} = -\\sum_{i=1}^n 2(y_i-mx_i-c)x_i.\n",
    "$$\n",
    "\n",
    "$$\n",
    "0 = -\\sum_{i=1}^n 2(y_ix_i-mx^2_i-cx_i)\n",
    "$$\n",
    "\n",
    "\n",
    "$$m^* = \\frac{\\sum_{i=1}^n (y_i - c)x_i}{\\sum_{i=1}^n x_i^2}$$\n",
    "\n",
    "Double differentiating it to find, whether it minimum or maximum point.\n",
    "\n",
    "$$\n",
    "\\frac{\\text{d}^2E(m,c)}{\\text{d}m^2} = 2x^2_i.\n",
    "$$\n",
    "\n",
    "The second derivative is positive, which in turn implies that we have found a minimum of the function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3998724072997095\n"
     ]
    }
   ],
   "source": [
    "m = ((y - c)*x).sum()/(x**2).sum()\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look at how good our fit is by computing the prediction across the input space. First create a vector of 'test points',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_test = np.linspace(1890, 2020, 130)[:, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use this vector to compute some test predictions,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_test = m*x_test + c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plot those test predictions with a blue line on the same plot as the data,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fb0336e5c0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_test, f_test, 'b-')\n",
    "plt.plot(x, y, 'rx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit isn't very good, we need to iterate between these parameter updates in a loop to improve the fit, we have to do this several times,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3987259642505432\n",
      "783.5273797273478\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(10):\n",
    "    m = ((y - c)*x).sum()/(x*x).sum()\n",
    "    c = (y-m*x).sum()/y.shape[0]\n",
    "print(m)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's try plotting the result again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1fb0336e438>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_test = m*x_test + c\n",
    "plt.plot(x_test, f_test, 'b-')\n",
    "plt.plot(x, y, 'rx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly we need more iterations than 10! In the next question you will add more iterations and report on the error as optimisation proceeds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Question 3\n",
    "\n",
    "There is a problem here, we seem to need many interations to get to a good solution. Let's explore what's going on. Write code which alternates between updates of `c` and `m`. Include the following features in your code.\n",
    "\n",
    "(a) Initialise with `m=-0.4` and `c=80`.\n",
    "(b) Every 10 iterations compute the value of the objective function for the training data and print it to the screen (you'll find hints on this in the lab from last week.\n",
    "(c) Cause the code to stop running when the error change over less than 10 iterations is smaller than $1\\times10^{-4}$. This is known as a stopping criterion.\n",
    "\n",
    "Why do we need so many iterations to get to the solution?\n",
    "\n",
    "*25 marks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute Error_Difference= 25.082467969685627 Object Function: 25.082467969685627\n",
      "Absolute Error_Difference= 0.1518525854377124 Object Function: 24.930615384247915\n",
      "Absolute Error_Difference= 0.1508544586776388 Object Function: 24.779760925570276\n",
      "Absolute Error_Difference= 0.1498628926029113 Object Function: 24.629898032967365\n",
      "Absolute Error_Difference= 0.14887784409015126 Object Function: 24.481020188877213\n",
      "Absolute Error_Difference= 0.14789927029954342 Object Function: 24.33312091857767\n",
      "Absolute Error_Difference= 0.14692712867237034 Object Function: 24.1861937899053\n",
      "Absolute Error_Difference= 0.14596137693038358 Object Function: 24.040232412974916\n",
      "Absolute Error_Difference= 0.14500197307297924 Object Function: 23.895230439901937\n",
      "Absolute Error_Difference= 0.14404887537524047 Object Function: 23.751181564526696\n",
      "Absolute Error_Difference= 0.14310204238672952 Object Function: 23.608079522139967\n",
      "Absolute Error_Difference= 0.14216143292982153 Object Function: 23.465918089210145\n",
      "Absolute Error_Difference= 0.14122700609703287 Object Function: 23.324691083113112\n",
      "Absolute Error_Difference= 0.14029872125026088 Object Function: 23.18439236186285\n",
      "Absolute Error_Difference= 0.13937653801776761 Object Function: 23.045015823845084\n",
      "Absolute Error_Difference= 0.13846041629419048 Object Function: 22.906555407550893\n",
      "Absolute Error_Difference= 0.13755031623682612 Object Function: 22.769005091314067\n",
      "Absolute Error_Difference= 0.13664619826558067 Object Function: 22.632358893048487\n",
      "Absolute Error_Difference= 0.1357480230599819 Object Function: 22.496610869988505\n",
      "Absolute Error_Difference= 0.13485575155825913 Object Function: 22.361755118430246\n",
      "Absolute Error_Difference= 0.1339693449555881 Object Function: 22.227785773474658\n",
      "Absolute Error_Difference= 0.13308876470176756 Object Function: 22.09469700877289\n",
      "Absolute Error_Difference= 0.13221397250028843 Object Function: 21.9624830362726\n",
      "Absolute Error_Difference= 0.1313449303063159 Object Function: 21.831138105966286\n",
      "Absolute Error_Difference= 0.1304816003251439 Object Function: 21.700656505641142\n",
      "Absolute Error_Difference= 0.12962394501025187 Object Function: 21.57103256063089\n",
      "Absolute Error_Difference= 0.12877192706220697 Object Function: 21.442260633568683\n",
      "Absolute Error_Difference= 0.12792550942648973 Object Function: 21.314335124142193\n",
      "Absolute Error_Difference= 0.12708465529244606 Object Function: 21.187250468849747\n",
      "Absolute Error_Difference= 0.12624932809075062 Object Function: 21.061001140758997\n",
      "Absolute Error_Difference= 0.12541949149328602 Object Function: 20.93558164926571\n",
      "Absolute Error_Difference= 0.12459510941047114 Object Function: 20.81098653985524\n",
      "Absolute Error_Difference= 0.1237761459893214 Object Function: 20.687210393865918\n",
      "Absolute Error_Difference= 0.1229625656132356 Object Function: 20.564247828252682\n",
      "Absolute Error_Difference= 0.12215433289955158 Object Function: 20.44209349535313\n",
      "Absolute Error_Difference= 0.12135141269778416 Object Function: 20.320742082655347\n",
      "Absolute Error_Difference= 0.12055377008923074 Object Function: 20.200188312566116\n",
      "Absolute Error_Difference= 0.11976137038390533 Object Function: 20.08042694218221\n",
      "Absolute Error_Difference= 0.11897417912032893 Object Function: 19.96145276306188\n",
      "Absolute Error_Difference= 0.11819216206356131 Object Function: 19.84326060099832\n",
      "Absolute Error_Difference= 0.11741528520333588 Object Function: 19.725845315794984\n",
      "Absolute Error_Difference= 0.1166435147534024 Object Function: 19.609201801041582\n",
      "Absolute Error_Difference= 0.11587681714923193 Object Function: 19.49332498389235\n",
      "Absolute Error_Difference= 0.11511515904661707 Object Function: 19.378209824845733\n",
      "Absolute Error_Difference= 0.1143585073215938 Object Function: 19.26385131752414\n",
      "Absolute Error_Difference= 0.11360682906676445 Object Function: 19.150244488457375\n",
      "Absolute Error_Difference= 0.11286009159201171 Object Function: 19.037384396865363\n",
      "Absolute Error_Difference= 0.11211826242109879 Object Function: 18.925266134444264\n",
      "Absolute Error_Difference= 0.11138130929179368 Object Function: 18.81388482515247\n",
      "Absolute Error_Difference= 0.11064920015420654 Object Function: 18.703235624998264\n",
      "Absolute Error_Difference= 0.10992190316863315 Object Function: 18.59331372182963\n",
      "Absolute Error_Difference= 0.10919938670468099 Object Function: 18.48411433512495\n",
      "Absolute Error_Difference= 0.10848161934009681 Object Function: 18.375632715784853\n",
      "Absolute Error_Difference= 0.10776856985915018 Object Function: 18.267864145925703\n",
      "Absolute Error_Difference= 0.1070602072510205 Object Function: 18.160803938674682\n",
      "Absolute Error_Difference= 0.10635650070901548 Object Function: 18.054447437965667\n",
      "Absolute Error_Difference= 0.10565741962880537 Object Function: 17.94879001833686\n",
      "Absolute Error_Difference= 0.10496293360708009 Object Function: 17.84382708472978\n",
      "Absolute Error_Difference= 0.10427301244104115 Object Function: 17.73955407228874\n",
      "Absolute Error_Difference= 0.10358762612522554 Object Function: 17.635966446163515\n",
      "Absolute Error_Difference= 0.10290674485252183 Object Function: 17.533059701310993\n",
      "Absolute Error_Difference= 0.10223033901100465 Object Function: 17.43082936229999\n",
      "Absolute Error_Difference= 0.1015583791839525 Object Function: 17.329270983116036\n",
      "Absolute Error_Difference= 0.10089083614754557 Object Function: 17.22838014696849\n",
      "Absolute Error_Difference= 0.10022768087024758 Object Function: 17.128152466098243\n",
      "Absolute Error_Difference= 0.09956888451136336 Object Function: 17.02858358158688\n",
      "Absolute Error_Difference= 0.0989144184197599 Object Function: 16.92966916316712\n",
      "Absolute Error_Difference= 0.0982642541325589 Object Function: 16.83140490903456\n",
      "Absolute Error_Difference= 0.09761836337382945 Object Function: 16.73378654566073\n",
      "Absolute Error_Difference= 0.09697671805402663 Object Function: 16.636809827606704\n",
      "Absolute Error_Difference= 0.09633929026765031 Object Function: 16.540470537339054\n",
      "Absolute Error_Difference= 0.0957060522929325 Object Function: 16.44476448504612\n",
      "Absolute Error_Difference= 0.09507697659010006 Object Function: 16.34968750845602\n",
      "Absolute Error_Difference= 0.09445203580103367 Object Function: 16.255235472654988\n",
      "Absolute Error_Difference= 0.09383120274626577 Object Function: 16.161404269908722\n",
      "Absolute Error_Difference= 0.09321445042613874 Object Function: 16.068189819482583\n",
      "Absolute Error_Difference= 0.09260175201788101 Object Function: 15.975588067464702\n",
      "Absolute Error_Difference= 0.09199308087508307 Object Function: 15.88359498658962\n",
      "Absolute Error_Difference= 0.09138841052659075 Object Function: 15.792206576063029\n",
      "Absolute Error_Difference= 0.09078771467503444 Object Function: 15.701418861387994\n",
      "Absolute Error_Difference= 0.0901909671964205 Object Function: 15.611227894191574\n",
      "Absolute Error_Difference= 0.08959814213776696 Object Function: 15.521629752053807\n",
      "Absolute Error_Difference= 0.08900921371695247 Object Function: 15.432620538336854\n",
      "Absolute Error_Difference= 0.08842415632174472 Object Function: 15.34419638201511\n",
      "Absolute Error_Difference= 0.08784294450765628 Object Function: 15.256353437507453\n",
      "Absolute Error_Difference= 0.08726555299772265 Object Function: 15.16908788450973\n",
      "Absolute Error_Difference= 0.08669195668106155 Object Function: 15.082395927828669\n",
      "Absolute Error_Difference= 0.08612213061199725 Object Function: 14.996273797216672\n",
      "Absolute Error_Difference= 0.08555605000859501 Object Function: 14.910717747208077\n",
      "Absolute Error_Difference= 0.08499369025194348 Object Function: 14.825724056956133\n",
      "Absolute Error_Difference= 0.08443502688483662 Object Function: 14.741289030071297\n",
      "Absolute Error_Difference= 0.08388003561102941 Object Function: 14.657408994460267\n",
      "Absolute Error_Difference= 0.08332869229395534 Object Function: 14.574080302166312\n",
      "Absolute Error_Difference= 0.08278097295531062 Object Function: 14.491299329211001\n",
      "Absolute Error_Difference= 0.08223685377486589 Object Function: 14.409062475436135\n",
      "Absolute Error_Difference= 0.08169631108893327 Object Function: 14.327366164347202\n",
      "Absolute Error_Difference= 0.08115932138901272 Object Function: 14.24620684295819\n",
      "Absolute Error_Difference= 0.08062586132114724 Object Function: 14.165580981637042\n",
      "Absolute Error_Difference= 0.08009590768567776 Object Function: 14.085485073951364\n",
      "Absolute Error_Difference= 0.07956943743407052 Object Function: 14.005915636517294\n",
      "Absolute Error_Difference= 0.07904642767097414 Object Function: 13.92686920884632\n",
      "Absolute Error_Difference= 0.07852685564954598 Object Function: 13.848342353196774\n",
      "Absolute Error_Difference= 0.07801069877428013 Object Function: 13.770331654422494\n",
      "Absolute Error_Difference= 0.07749793459714915 Object Function: 13.692833719825344\n",
      "Absolute Error_Difference= 0.07698854081801265 Object Function: 13.615845179007332\n",
      "Absolute Error_Difference= 0.07648249528321038 Object Function: 13.539362683724121\n",
      "Absolute Error_Difference= 0.07597977598483041 Object Function: 13.463382907739291\n",
      "Absolute Error_Difference= 0.07548036105936795 Object Function: 13.387902546679923\n",
      "Absolute Error_Difference= 0.0749842287873026 Object Function: 13.31291831789262\n",
      "Absolute Error_Difference= 0.07449135759170744 Object Function: 13.238426960300913\n",
      "Absolute Error_Difference= 0.07400172603761312 Object Function: 13.1644252342633\n",
      "Absolute Error_Difference= 0.07351531283084256 Object Function: 13.090909921432457\n",
      "Absolute Error_Difference= 0.07303209681696643 Object Function: 13.017877824615491\n",
      "Absolute Error_Difference= 0.0725520569813849 Object Function: 12.945325767634106\n",
      "Absolute Error_Difference= 0.0720751724464801 Object Function: 12.873250595187626\n",
      "Absolute Error_Difference= 0.07160142247280277 Object Function: 12.801649172714823\n",
      "Absolute Error_Difference= 0.07113078645688198 Object Function: 12.730518386257941\n",
      "Absolute Error_Difference= 0.0706632439304915 Object Function: 12.65985514232745\n",
      "Absolute Error_Difference= 0.07019877456026968 Object Function: 12.58965636776718\n",
      "Absolute Error_Difference= 0.06973735814652748 Object Function: 12.519919009620653\n",
      "Absolute Error_Difference= 0.06927897462179011 Object Function: 12.450640034998862\n",
      "Absolute Error_Difference= 0.06882360405122867 Object Function: 12.381816430947634\n",
      "Absolute Error_Difference= 0.06837122663048412 Object Function: 12.31344520431715\n",
      "Absolute Error_Difference= 0.06792182268581115 Object Function: 12.245523381631338\n",
      "Absolute Error_Difference= 0.06747537267227521 Object Function: 12.178048008959063\n",
      "Absolute Error_Difference= 0.06703185717395677 Object Function: 12.111016151785106\n",
      "Absolute Error_Difference= 0.0665912569020648 Object Function: 12.044424894883042\n",
      "Absolute Error_Difference= 0.0661535526950523 Object Function: 11.97827134218799\n",
      "Absolute Error_Difference= 0.06571872551690383 Object Function: 11.912552616671086\n",
      "Absolute Error_Difference= 0.06528675645705206 Object Function: 11.847265860214033\n",
      "Absolute Error_Difference= 0.06485762672898154 Object Function: 11.782408233485052\n",
      "Absolute Error_Difference= 0.06443131766982901 Object Function: 11.717976915815223\n",
      "Absolute Error_Difference= 0.06400781073932826 Object Function: 11.653969105075895\n",
      "Absolute Error_Difference= 0.06358708751900899 Object Function: 11.590382017556886\n",
      "Absolute Error_Difference= 0.06316912971167987 Object Function: 11.527212887845206\n",
      "Absolute Error_Difference= 0.06275391914026507 Object Function: 11.46445896870494\n",
      "Absolute Error_Difference= 0.06234143774720735 Object Function: 11.402117530957733\n",
      "Absolute Error_Difference= 0.06193166759343249 Object Function: 11.340185863364301\n",
      "Absolute Error_Difference= 0.06152459085816275 Object Function: 11.278661272506138\n",
      "Absolute Error_Difference= 0.06112018983759171 Object Function: 11.217541082668546\n",
      "Absolute Error_Difference= 0.0607184469440778 Object Function: 11.156822635724469\n",
      "Absolute Error_Difference= 0.06031934470592226 Object Function: 11.096503291018546\n",
      "Absolute Error_Difference= 0.05992286576601202 Object Function: 11.036580425252534\n",
      "Absolute Error_Difference= 0.059528992881386245 Object Function: 10.977051432371148\n",
      "Absolute Error_Difference= 0.059137708922547105 Object Function: 10.917913723448601\n",
      "Absolute Error_Difference= 0.058748996872390435 Object Function: 10.85916472657621\n",
      "Absolute Error_Difference= 0.05836283982585222 Object Function: 10.800801886750358\n",
      "Absolute Error_Difference= 0.05797922098883035 Object Function: 10.742822665761528\n",
      "Absolute Error_Difference= 0.05759812367772632 Object Function: 10.685224542083802\n",
      "Absolute Error_Difference= 0.05721953131854285 Object Function: 10.628005010765259\n",
      "Absolute Error_Difference= 0.05684342744621951 Object Function: 10.57116158331904\n",
      "Absolute Error_Difference= 0.05646979570395061 Object Function: 10.514691787615089\n",
      "Absolute Error_Difference= 0.05609861984239828 Object Function: 10.45859316777269\n",
      "Absolute Error_Difference= 0.0557298837191329 Object Function: 10.402863284053558\n",
      "Absolute Error_Difference= 0.05536357129771652 Object Function: 10.347499712755841\n",
      "Absolute Error_Difference= 0.05499966664707401 Object Function: 10.292500046108767\n",
      "Absolute Error_Difference= 0.05463815394111471 Object Function: 10.237861892167652\n",
      "Absolute Error_Difference= 0.05427901745748365 Object Function: 10.183582874710169\n",
      "Absolute Error_Difference= 0.05392224157720804 Object Function: 10.12966063313296\n",
      "Absolute Error_Difference= 0.053567810784226566 Object Function: 10.076092822348734\n",
      "Absolute Error_Difference= 0.053215709664190314 Object Function: 10.022877112684544\n",
      "Absolute Error_Difference= 0.052865922903993834 Object Function: 9.97001118978055\n",
      "Absolute Error_Difference= 0.0525184352916952 Object Function: 9.917492754488855\n",
      "Absolute Error_Difference= 0.052173231714757407 Object Function: 9.865319522774097\n",
      "Absolute Error_Difference= 0.05183029716029175 Object Function: 9.813489225613806\n",
      "Absolute Error_Difference= 0.05148961671398489 Object Function: 9.76199960889982\n",
      "Absolute Error_Difference= 0.05115117555965121 Object Function: 9.71084843334017\n",
      "Absolute Error_Difference= 0.05081495897839261 Object Function: 9.660033474361777\n",
      "Absolute Error_Difference= 0.05048095234804428 Object Function: 9.609552522013733\n",
      "Absolute Error_Difference= 0.05014914114270752 Object Function: 9.559403380871025\n",
      "Absolute Error_Difference= 0.0498195109317745 Object Function: 9.50958386993925\n",
      "Absolute Error_Difference= 0.04949204737963697 Object Function: 9.460091822559614\n",
      "Absolute Error_Difference= 0.04916673624473766 Object Function: 9.410925086314876\n",
      "Absolute Error_Difference= 0.04884356337941398 Object Function: 9.362081522935462\n",
      "Absolute Error_Difference= 0.04852251472865454 Object Function: 9.313559008206807\n",
      "Absolute Error_Difference= 0.048203576330129394 Object Function: 9.265355431876678\n",
      "Absolute Error_Difference= 0.04788673431304957 Object Function: 9.217468697563628\n",
      "Absolute Error_Difference= 0.047571974897985925 Object Function: 9.169896722665642\n",
      "Absolute Error_Difference= 0.04725928439599514 Object Function: 9.122637438269647\n",
      "Absolute Error_Difference= 0.04694864920804598 Object Function: 9.075688789061601\n",
      "Absolute Error_Difference= 0.04664005582463915 Object Function: 9.029048733236962\n",
      "Absolute Error_Difference= 0.04633349082490312 Object Function: 8.982715242412059\n",
      "Absolute Error_Difference= 0.0460289408764023 Object Function: 8.936686301535657\n",
      "Absolute Error_Difference= 0.04572639273411383 Object Function: 8.890959908801543\n",
      "Absolute Error_Difference= 0.04542583324021443 Object Function: 8.845534075561329\n",
      "Absolute Error_Difference= 0.045127249323321905 Object Function: 8.800406826238007\n",
      "Absolute Error_Difference= 0.04483062799790538 Object Function: 8.755576198240101\n",
      "Absolute Error_Difference= 0.04453595636395313 Object Function: 8.711040241876148\n",
      "Absolute Error_Difference= 0.04424322160605776 Object Function: 8.66679702027009\n",
      "Absolute Error_Difference= 0.04395241099319769 Object Function: 8.622844609276893\n",
      "Absolute Error_Difference= 0.0436635118779396 Object Function: 8.579181097398953\n",
      "Absolute Error_Difference= 0.04337651169603873 Object Function: 8.535804585702914\n",
      "Absolute Error_Difference= 0.04309139796587225 Object Function: 8.492713187737042\n",
      "Absolute Error_Difference= 0.042808158287526155 Object Function: 8.449905029449516\n",
      "Absolute Error_Difference= 0.04252678034326962 Object Function: 8.407378249106246\n",
      "Absolute Error_Difference= 0.042247251895622284 Object Function: 8.365130997210624\n",
      "Absolute Error_Difference= 0.04196956078790137 Object Function: 8.323161436422723\n",
      "Absolute Error_Difference= 0.0416936949433353 Object Function: 8.281467741479387\n",
      "Absolute Error_Difference= 0.041419642364486364 Object Function: 8.240048099114901\n",
      "Absolute Error_Difference= 0.04114739113267518 Object Function: 8.198900707982226\n",
      "Absolute Error_Difference= 0.04087692940773735 Object Function: 8.158023778574488\n",
      "Absolute Error_Difference= 0.04060824542719921 Object Function: 8.11741553314729\n",
      "Absolute Error_Difference= 0.0403413275060025 Object Function: 8.077074205641287\n",
      "Absolute Error_Difference= 0.04007616403574232 Object Function: 8.036998041605544\n",
      "Absolute Error_Difference= 0.03981274348450192 Object Function: 7.9971852981210425\n",
      "Absolute Error_Difference= 0.03955105439601425 Object Function: 7.957634243725028\n",
      "Absolute Error_Difference= 0.03929108538945769 Object Function: 7.918343158335571\n",
      "Absolute Error_Difference= 0.0390328251587011 Object Function: 7.8793103331768695\n",
      "Absolute Error_Difference= 0.038776262471946765 Object Function: 7.840534070704923\n",
      "Absolute Error_Difference= 0.03852138617127032 Object Function: 7.802012684533652\n",
      "Absolute Error_Difference= 0.03826818517202657 Object Function: 7.763744499361626\n",
      "Absolute Error_Difference= 0.038016648462446234 Object Function: 7.72572785089918\n",
      "Absolute Error_Difference= 0.03776676510321764 Object Function: 7.687961085795962\n",
      "Absolute Error_Difference= 0.037518524226837435 Object Function: 7.6504425615691245\n",
      "Absolute Error_Difference= 0.03727191503728289 Object Function: 7.613170646531842\n",
      "Absolute Error_Difference= 0.03702692680948161 Object Function: 7.57614371972236\n",
      "Absolute Error_Difference= 0.03678354888879021 Object Function: 7.53936017083357\n",
      "Absolute Error_Difference= 0.036541770690758923 Object Function: 7.502818400142811\n",
      "Absolute Error_Difference= 0.036301581700381114 Object Function: 7.46651681844243\n",
      "Absolute Error_Difference= 0.03606297147175219 Object Function: 7.430453846970678\n",
      "Absolute Error_Difference= 0.0358259296277641 Object Function: 7.3946279173429135\n",
      "Absolute Error_Difference= 0.03559044585925797 Object Function: 7.3590374714836555\n",
      "Absolute Error_Difference= 0.03535650992524175 Object Function: 7.323680961558414\n",
      "Absolute Error_Difference= 0.035124111651638756 Object Function: 7.288556849906775\n",
      "Absolute Error_Difference= 0.03489324093143775 Object Function: 7.253663608975337\n",
      "Absolute Error_Difference= 0.03466388772408191 Object Function: 7.218999721251255\n",
      "Absolute Error_Difference= 0.034436042054918126 Object Function: 7.184563679196337\n",
      "Absolute Error_Difference= 0.03420969401486662 Object Function: 7.150353985181471\n",
      "Absolute Error_Difference= 0.03398483376010297 Object Function: 7.116369151421368\n",
      "Absolute Error_Difference= 0.033761451511366225 Object Function: 7.082607699910001\n",
      "Absolute Error_Difference= 0.033539537553775034 Object Function: 7.049068162356226\n",
      "Absolute Error_Difference= 0.03331908223611357 Object Function: 7.015749080120113\n",
      "Absolute Error_Difference= 0.033100075970962095 Object Function: 6.982649004149151\n",
      "Absolute Error_Difference= 0.0328825092334597 Object Function: 6.949766494915691\n",
      "Absolute Error_Difference= 0.03266637256183369 Object Function: 6.917100122353857\n",
      "Absolute Error_Difference= 0.032451656556049535 Object Function: 6.884648465797808\n",
      "Absolute Error_Difference= 0.03223835187821855 Object Function: 6.852410113919589\n",
      "Absolute Error_Difference= 0.03202644925160225 Object Function: 6.820383664667987\n",
      "Absolute Error_Difference= 0.03181593946059902 Object Function: 6.788567725207388\n",
      "Absolute Error_Difference= 0.031606813350045115 Object Function: 6.756960911857343\n",
      "Absolute Error_Difference= 0.031399061825012176 Object Function: 6.725561850032331\n",
      "Absolute Error_Difference= 0.031192675850372886 Object Function: 6.694369174181958\n",
      "Absolute Error_Difference= 0.030987646450342687 Object Function: 6.663381527731615\n",
      "Absolute Error_Difference= 0.030783964708194667 Object Function: 6.63259756302342\n",
      "Absolute Error_Difference= 0.030581621765755962 Object Function: 6.6020159412576644\n",
      "Absolute Error_Difference= 0.030380608823095123 Object Function: 6.571635332434569\n",
      "Absolute Error_Difference= 0.030180917138135754 Object Function: 6.541454415296434\n",
      "Absolute Error_Difference= 0.0299825380262293 Object Function: 6.511471877270204\n",
      "Absolute Error_Difference= 0.029785462859866385 Object Function: 6.481686414410338\n",
      "Absolute Error_Difference= 0.029589683068196315 Object Function: 6.452096731342142\n",
      "Absolute Error_Difference= 0.029395190136771276 Object Function: 6.42270154120537\n",
      "Absolute Error_Difference= 0.029201975606985897 Object Function: 6.393499565598384\n",
      "Absolute Error_Difference= 0.029010031075923592 Object Function: 6.364489534522461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute Error_Difference= 0.028819348195928463 Object Function: 6.335670186326532\n",
      "Absolute Error_Difference= 0.028629918674150545 Object Function: 6.307040267652382\n",
      "Absolute Error_Difference= 0.02844173427227137 Object Function: 6.27859853338011\n",
      "Absolute Error_Difference= 0.028254786806061638 Object Function: 6.250343746574049\n",
      "Absolute Error_Difference= 0.028069068145279985 Object Function: 6.222274678428769\n",
      "Absolute Error_Difference= 0.02788457021281321 Object Function: 6.194390108215956\n",
      "Absolute Error_Difference= 0.02770128498497293 Object Function: 6.166688823230983\n",
      "Absolute Error_Difference= 0.027519204490611848 Object Function: 6.139169618740371\n",
      "Absolute Error_Difference= 0.027338320810951444 Object Function: 6.111831297929419\n",
      "Absolute Error_Difference= 0.02715862607940256 Object Function: 6.084672671850017\n",
      "Absolute Error_Difference= 0.026980112481003182 Object Function: 6.057692559369014\n",
      "Absolute Error_Difference= 0.026802772252119134 Object Function: 6.0308897871168945\n",
      "Absolute Error_Difference= 0.026626597680225572 Object Function: 6.004263189436669\n",
      "Absolute Error_Difference= 0.02645158110345669 Object Function: 5.977811608333212\n",
      "Absolute Error_Difference= 0.02627771491040498 Object Function: 5.951533893422807\n",
      "Absolute Error_Difference= 0.026104991539416922 Object Function: 5.92542890188339\n",
      "Absolute Error_Difference= 0.02593340347886741 Object Function: 5.899495498404523\n",
      "Absolute Error_Difference= 0.025762943266298244 Object Function: 5.873732555138225\n",
      "Absolute Error_Difference= 0.025593603488426098 Object Function: 5.848138951649799\n",
      "Absolute Error_Difference= 0.025425376780553677 Object Function: 5.822713574869245\n",
      "Absolute Error_Difference= 0.02525825582652974 Object Function: 5.797455319042715\n",
      "Absolute Error_Difference= 0.025092233358233074 Object Function: 5.772363085684482\n",
      "Absolute Error_Difference= 0.024927302155314912 Object Function: 5.747435783529167\n",
      "Absolute Error_Difference= 0.02476345504484634 Object Function: 5.722672328484321\n",
      "Absolute Error_Difference= 0.02460068490114864 Object Function: 5.698071643583172\n",
      "Absolute Error_Difference= 0.024438984645350992 Object Function: 5.673632658937821\n",
      "Absolute Error_Difference= 0.02427834724497302 Object Function: 5.649354311692848\n",
      "Absolute Error_Difference= 0.024118765713968315 Object Function: 5.62523554597888\n",
      "Absolute Error_Difference= 0.023960233112003237 Object Function: 5.601275312866877\n",
      "Absolute Error_Difference= 0.023802742544596356 Object Function: 5.57747257032228\n",
      "Absolute Error_Difference= 0.02364628716235373 Object Function: 5.5538262831599265\n",
      "Absolute Error_Difference= 0.023490860161112792 Object Function: 5.530335422998814\n",
      "Absolute Error_Difference= 0.023336454781180294 Object Function: 5.5069989682176335\n",
      "Absolute Error_Difference= 0.023183064307545465 Object Function: 5.483815903910088\n",
      "Absolute Error_Difference= 0.02303068206923875 Object Function: 5.460785221840849\n",
      "Absolute Error_Difference= 0.022879301439114208 Object Function: 5.437905920401735\n",
      "Absolute Error_Difference= 0.022728915833502228 Object Function: 5.415177004568233\n",
      "Absolute Error_Difference= 0.022579518712277924 Object Function: 5.392597485855955\n",
      "Absolute Error_Difference= 0.022431103577979172 Object Function: 5.370166382277976\n",
      "Absolute Error_Difference= 0.022283663976146784 Object Function: 5.347882718301829\n",
      "Absolute Error_Difference= 0.022137193494529583 Object Function: 5.325745524807299\n",
      "Absolute Error_Difference= 0.02199168576307553 Object Function: 5.303753839044224\n",
      "Absolute Error_Difference= 0.021847134453669703 Object Function: 5.281906704590554\n",
      "Absolute Error_Difference= 0.02170353327981811 Object Function: 5.260203171310736\n",
      "Absolute Error_Difference= 0.02156087599611567 Object Function: 5.23864229531462\n",
      "Absolute Error_Difference= 0.021419156398521544 Object Function: 5.217223138916099\n",
      "Absolute Error_Difference= 0.021278368323587316 Object Function: 5.1959447705925115\n",
      "Absolute Error_Difference= 0.021138505648421457 Object Function: 5.17480626494409\n",
      "Absolute Error_Difference= 0.020999562290342944 Object Function: 5.153806702653747\n",
      "Absolute Error_Difference= 0.020861532206655653 Object Function: 5.132945170447091\n",
      "Absolute Error_Difference= 0.020724409394518695 Object Function: 5.112220761052573\n",
      "Absolute Error_Difference= 0.020588187890349552 Object Function: 5.091632573162223\n",
      "Absolute Error_Difference= 0.02045286176978145 Object Function: 5.071179711392442\n",
      "Absolute Error_Difference= 0.020318425147664243 Object Function: 5.0508612862447775\n",
      "Absolute Error_Difference= 0.02018487217716647 Object Function: 5.030676414067611\n",
      "Absolute Error_Difference= 0.020052197050130616 Object Function: 5.01062421701748\n",
      "Absolute Error_Difference= 0.01992039399640788 Object Function: 4.9907038230210725\n",
      "Absolute Error_Difference= 0.019789457283923007 Object Function: 4.9709143657371495\n",
      "Absolute Error_Difference= 0.019659381218217753 Object Function: 4.951254984518932\n",
      "Absolute Error_Difference= 0.019530160142231523 Object Function: 4.9317248243767\n",
      "Absolute Error_Difference= 0.019401788436181455 Object Function: 4.912323035940519\n",
      "Absolute Error_Difference= 0.01927426051707304 Object Function: 4.893048775423446\n",
      "Absolute Error_Difference= 0.01914757083872587 Object Function: 4.87390120458472\n",
      "Absolute Error_Difference= 0.019021713891448577 Object Function: 4.854879490693271\n",
      "Absolute Error_Difference= 0.018896684201633818 Object Function: 4.8359828064916375\n",
      "Absolute Error_Difference= 0.018772476331691657 Object Function: 4.817210330159946\n",
      "Absolute Error_Difference= 0.018649084879878153 Object Function: 4.798561245280068\n",
      "Absolute Error_Difference= 0.018526504479838835 Object Function: 4.780034740800229\n",
      "Absolute Error_Difference= 0.01840472980056429 Object Function: 4.7616300109996645\n",
      "Absolute Error_Difference= 0.018283755545991376 Object Function: 4.743346255453673\n",
      "Absolute Error_Difference= 0.018163576454998775 Object Function: 4.725182678998674\n",
      "Absolute Error_Difference= 0.01804418730092916 Object Function: 4.707138491697745\n",
      "Absolute Error_Difference= 0.017925582891566094 Object Function: 4.689212908806179\n",
      "Absolute Error_Difference= 0.017807758068754787 Object Function: 4.671405150737424\n",
      "Absolute Error_Difference= 0.01769070770826886 Object Function: 4.6537144430291555\n",
      "Absolute Error_Difference= 0.01757442671959275 Object Function: 4.636140016309563\n",
      "Absolute Error_Difference= 0.017458910045649034 Object Function: 4.618681106263914\n",
      "Absolute Error_Difference= 0.017344152662591483 Object Function: 4.601336953601322\n",
      "Absolute Error_Difference= 0.01723014957955815 Object Function: 4.584106804021764\n",
      "Absolute Error_Difference= 0.01711689583860032 Object Function: 4.566989908183164\n",
      "Absolute Error_Difference= 0.0170043865142695 Object Function: 4.549985521668894\n",
      "Absolute Error_Difference= 0.016892616713513497 Object Function: 4.533092904955381\n",
      "Absolute Error_Difference= 0.016781581575463278 Object Function: 4.5163113233799175\n",
      "Absolute Error_Difference= 0.016671276271154944 Object Function: 4.4996400471087625\n",
      "Absolute Error_Difference= 0.016561696003432935 Object Function: 4.48307835110533\n",
      "Absolute Error_Difference= 0.01645283600657077 Object Function: 4.466625515098759\n",
      "Absolute Error_Difference= 0.01634469154628171 Object Function: 4.450280823552477\n",
      "Absolute Error_Difference= 0.016237257919306636 Object Function: 4.4340435656331705\n",
      "Absolute Error_Difference= 0.01613053045338564 Object Function: 4.417913035179785\n",
      "Absolute Error_Difference= 0.01602450450687254 Object Function: 4.401888530672912\n",
      "Absolute Error_Difference= 0.015919175468737556 Object Function: 4.385969355204175\n",
      "Absolute Error_Difference= 0.015814538758165853 Object Function: 4.370154816446009\n",
      "Absolute Error_Difference= 0.015710589824448284 Object Function: 4.354444226621561\n",
      "Absolute Error_Difference= 0.015607324146934332 Object Function: 4.338836902474626\n",
      "Absolute Error_Difference= 0.015504737234538268 Object Function: 4.323332165240088\n",
      "Absolute Error_Difference= 0.015402824625669886 Object Function: 4.307929340614418\n",
      "Absolute Error_Difference= 0.015301581888240712 Object Function: 4.292627758726177\n",
      "Absolute Error_Difference= 0.015201004619067149 Object Function: 4.27742675410711\n",
      "Absolute Error_Difference= 0.015101088444190225 Object Function: 4.26232566566292\n",
      "Absolute Error_Difference= 0.015001829018072677 Object Function: 4.247323836644847\n",
      "Absolute Error_Difference= 0.014903222023999518 Object Function: 4.232420614620848\n",
      "Absolute Error_Difference= 0.01480526317352382 Object Function: 4.217615351447324\n",
      "Absolute Error_Difference= 0.014707948206354793 Object Function: 4.202907403240969\n",
      "Absolute Error_Difference= 0.014611272890332927 Object Function: 4.188296130350636\n",
      "Absolute Error_Difference= 0.01451523302091573 Object Function: 4.173780897329721\n",
      "Absolute Error_Difference= 0.014419824421441518 Object Function: 4.159361072908279\n",
      "Absolute Error_Difference= 0.014325042942502364 Object Function: 4.145036029965777\n",
      "Absolute Error_Difference= 0.014230884462049787 Object Function: 4.130805145503727\n",
      "Absolute Error_Difference= 0.014137344885076786 Object Function: 4.11666780061865\n",
      "Absolute Error_Difference= 0.014044420143625835 Object Function: 4.102623380475024\n",
      "Absolute Error_Difference= 0.013952106196245317 Object Function: 4.088671274278779\n",
      "Absolute Error_Difference= 0.013860399028347459 Object Function: 4.0748108752504315\n",
      "Absolute Error_Difference= 0.013769294651419628 Object Function: 4.061041580599012\n",
      "Absolute Error_Difference= 0.013678789103484412 Object Function: 4.0473627914955275\n",
      "Absolute Error_Difference= 0.013588878448272723 Object Function: 4.033773913047255\n",
      "Absolute Error_Difference= 0.013499558775637688 Object Function: 4.020274354271617\n",
      "Absolute Error_Difference= 0.013410826201083914 Object Function: 4.006863528070533\n",
      "Absolute Error_Difference= 0.01332267686552191 Object Function: 3.9935408512050112\n",
      "Absolute Error_Difference= 0.013235106935415075 Object Function: 3.980305744269596\n",
      "Absolute Error_Difference= 0.013148112602278772 Object Function: 3.9671576316673174\n",
      "Absolute Error_Difference= 0.013061690082746491 Object Function: 3.954095941584571\n",
      "Absolute Error_Difference= 0.012975835618256326 Object Function: 3.9411201059663146\n",
      "Absolute Error_Difference= 0.012890545475007453 Object Function: 3.928229560491307\n",
      "Absolute Error_Difference= 0.012805815943746968 Object Function: 3.91542374454756\n",
      "Absolute Error_Difference= 0.012721643339454136 Object Function: 3.902702101208106\n",
      "Absolute Error_Difference= 0.012638024001609072 Object Function: 3.890064077206497\n",
      "Absolute Error_Difference= 0.012554954293475973 Object Function: 3.877509122913021\n",
      "Absolute Error_Difference= 0.01247243060239267 Object Function: 3.8650366923106283\n",
      "Absolute Error_Difference= 0.012390449339370502 Object Function: 3.852646242971258\n",
      "Absolute Error_Difference= 0.012309006939039246 Object Function: 3.8403372360322185\n",
      "Absolute Error_Difference= 0.012228099859445063 Object Function: 3.8281091361727735\n",
      "Absolute Error_Difference= 0.012147724581975439 Object Function: 3.815961411590798\n",
      "Absolute Error_Difference= 0.012067877610992817 Object Function: 3.8038935339798052\n",
      "Absolute Error_Difference= 0.011988555474026885 Object Function: 3.7919049785057783\n",
      "Absolute Error_Difference= 0.011909754721339372 Object Function: 3.779995223784439\n",
      "Absolute Error_Difference= 0.011831471925832115 Object Function: 3.768163751858607\n",
      "Absolute Error_Difference= 0.011753703683015537 Object Function: 3.7564100481755913\n",
      "Absolute Error_Difference= 0.011676446610639601 Object Function: 3.7447336015649517\n",
      "Absolute Error_Difference= 0.011599697348927407 Object Function: 3.7331339042160243\n",
      "Absolute Error_Difference= 0.011523452559957903 Object Function: 3.7216104516560664\n",
      "Absolute Error_Difference= 0.01144770892785063 Object Function: 3.710162742728216\n",
      "Absolute Error_Difference= 0.011372463158473956 Object Function: 3.698790279569742\n",
      "Absolute Error_Difference= 0.011297711979382896 Object Function: 3.687492567590359\n",
      "Absolute Error_Difference= 0.01122345213967968 Object Function: 3.6762691154506792\n",
      "Absolute Error_Difference= 0.01114968040977038 Object Function: 3.665119435040909\n",
      "Absolute Error_Difference= 0.0110763935812761 Object Function: 3.6540430414596328\n",
      "Absolute Error_Difference= 0.011003588466999226 Object Function: 3.6430394529926335\n",
      "Absolute Error_Difference= 0.010931261900604117 Object Function: 3.6321081910920294\n",
      "Absolute Error_Difference= 0.010859410736538955 Object Function: 3.6212487803554905\n",
      "Absolute Error_Difference= 0.01078803185012056 Object Function: 3.61046074850537\n",
      "Absolute Error_Difference= 0.010717122136920665 Object Function: 3.5997436263684492\n",
      "Absolute Error_Difference= 0.010646678513189567 Object Function: 3.5890969478552597\n",
      "Absolute Error_Difference= 0.010576697915206434 Object Function: 3.5785202499400532\n",
      "Absolute Error_Difference= 0.010507177299606152 Object Function: 3.568013072640447\n",
      "Absolute Error_Difference= 0.010438113642878832 Object Function: 3.5575749589975683\n",
      "Absolute Error_Difference= 0.01036950394142977 Object Function: 3.5472054550561385\n",
      "Absolute Error_Difference= 0.010301345211394253 Object Function: 3.5369041098447442\n",
      "Absolute Error_Difference= 0.010233634488605148 Object Function: 3.526670475356139\n",
      "Absolute Error_Difference= 0.010166368828271377 Object Function: 3.5165041065278677\n",
      "Absolute Error_Difference= 0.010099545304956159 Object Function: 3.5064045612229116\n",
      "Absolute Error_Difference= 0.010033161012560576 Object Function: 3.496371400210351\n",
      "Absolute Error_Difference= 0.009967213063997615 Object Function: 3.4864041871463534\n",
      "Absolute Error_Difference= 0.009901698591166852 Object Function: 3.4765024885551865\n",
      "Absolute Error_Difference= 0.009836614744878514 Object Function: 3.466665873810308\n",
      "Absolute Error_Difference= 0.009771958694526628 Object Function: 3.4568939151157814\n",
      "Absolute Error_Difference= 0.009707727628312846 Object Function: 3.4471861874874685\n",
      "Absolute Error_Difference= 0.009643918752780145 Object Function: 3.4375422687346884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute Error_Difference= 0.009580529292859019 Object Function: 3.4279617394418294\n",
      "Absolute Error_Difference= 0.009517556491720036 Object Function: 3.4184441829501093\n",
      "Absolute Error_Difference= 0.009454997610717442 Object Function: 3.408989185339392\n",
      "Absolute Error_Difference= 0.009392849929105829 Object Function: 3.399596335410286\n",
      "Absolute Error_Difference= 0.009331110744091653 Object Function: 3.3902652246661944\n",
      "Absolute Error_Difference= 0.009269777370615184 Object Function: 3.380995447295579\n",
      "Absolute Error_Difference= 0.00920884714129988 Object Function: 3.3717866001542793\n",
      "Absolute Error_Difference= 0.009148317406284967 Object Function: 3.3626382827479944\n",
      "Absolute Error_Difference= 0.009088185533068227 Object Function: 3.353550097214926\n",
      "Absolute Error_Difference= 0.009028448906553965 Object Function: 3.344521648308372\n",
      "Absolute Error_Difference= 0.008969104928772342 Object Function: 3.3355525433796\n",
      "Absolute Error_Difference= 0.00891015101886472 Object Function: 3.326642392360735\n",
      "Absolute Error_Difference= 0.00885158461289759 Object Function: 3.3177908077478375\n",
      "Absolute Error_Difference= 0.008793403163789293 Object Function: 3.3089974045840482\n",
      "Absolute Error_Difference= 0.008735604141233644 Object Function: 3.3002618004428146\n",
      "Absolute Error_Difference= 0.008678185031557817 Object Function: 3.2915836154112568\n",
      "Absolute Error_Difference= 0.008621143337574022 Object Function: 3.2829624720736827\n",
      "Absolute Error_Difference= 0.00856447657854087 Object Function: 3.274397995495142\n",
      "Absolute Error_Difference= 0.008508182290030142 Object Function: 3.2658898132051117\n",
      "Absolute Error_Difference= 0.00845225802372207 Object Function: 3.2574375551813897\n",
      "Absolute Error_Difference= 0.008396701347554991 Object Function: 3.2490408538338347\n",
      "Absolute Error_Difference= 0.008341509845302575 Object Function: 3.240699343988532\n",
      "Absolute Error_Difference= 0.008286681116697725 Object Function: 3.2324126628718344\n",
      "Absolute Error_Difference= 0.008232212777224746 Object Function: 3.2241804500946096\n",
      "Absolute Error_Difference= 0.008178102458017644 Object Function: 3.216002347636592\n",
      "Absolute Error_Difference= 0.008124347805859244 Object Function: 3.2078779998307327\n",
      "Absolute Error_Difference= 0.008070946482954255 Object Function: 3.1998070533477785\n",
      "Absolute Error_Difference= 0.008017896166809813 Object Function: 3.1917891571809687\n",
      "Absolute Error_Difference= 0.007965194550283439 Object Function: 3.1838239626306852\n",
      "Absolute Error_Difference= 0.007912839341420508 Object Function: 3.1759111232892647\n",
      "Absolute Error_Difference= 0.00786082826321488 Object Function: 3.16805029502605\n",
      "Absolute Error_Difference= 0.00780915905377455 Object Function: 3.1602411359722753\n",
      "Absolute Error_Difference= 0.007757829465889543 Object Function: 3.1524833065063858\n",
      "Absolute Error_Difference= 0.00770683726733612 Object Function: 3.1447764692390496\n",
      "Absolute Error_Difference= 0.0076561802403993795 Object Function: 3.1371202889986503\n",
      "Absolute Error_Difference= 0.007605856181994497 Object Function: 3.1295144328166558\n",
      "Absolute Error_Difference= 0.007555862903536159 Object Function: 3.1219585699131196\n",
      "Absolute Error_Difference= 0.007506198230792904 Object Function: 3.1144523716823267\n",
      "Absolute Error_Difference= 0.007456860003860477 Object Function: 3.106995511678466\n",
      "Absolute Error_Difference= 0.00740784607702949 Object Function: 3.0995876656014367\n",
      "Absolute Error_Difference= 0.007359154318614003 Object Function: 3.0922285112828227\n",
      "Absolute Error_Difference= 0.007310782611051003 Object Function: 3.0849177286717717\n",
      "Absolute Error_Difference= 0.0072627288505855425 Object Function: 3.077654999821186\n",
      "Absolute Error_Difference= 0.007214990947475908 Object Function: 3.0704400088737103\n",
      "Absolute Error_Difference= 0.007167566825461158 Object Function: 3.063272442048249\n",
      "Absolute Error_Difference= 0.0071204544221203925 Object Function: 3.0561519876261287\n",
      "Absolute Error_Difference= 0.007073651688528582 Object Function: 3.0490783359376\n",
      "Absolute Error_Difference= 0.007027156589209049 Object Function: 3.042051179348391\n",
      "Absolute Error_Difference= 0.006980967102080182 Object Function: 3.035070212246311\n",
      "Absolute Error_Difference= 0.00693508121840436 Object Function: 3.0281351310279065\n",
      "Absolute Error_Difference= 0.0068894969424979635 Object Function: 3.0212456340854086\n",
      "Absolute Error_Difference= 0.006844212292012486 Object Function: 3.014401421793396\n",
      "Absolute Error_Difference= 0.006799225297400291 Object Function: 3.007602196495996\n",
      "Absolute Error_Difference= 0.006754534002222368 Object Function: 3.0008476624937734\n",
      "Absolute Error_Difference= 0.006710136462896532 Object Function: 2.994137526030877\n",
      "Absolute Error_Difference= 0.006666030748457619 Object Function: 2.9874714952824193\n",
      "Absolute Error_Difference= 0.006622214940821269 Object Function: 2.980849280341598\n",
      "Absolute Error_Difference= 0.00657868713438603 Object Function: 2.974270593207212\n",
      "Absolute Error_Difference= 0.006535445436187892 Object Function: 2.967735147771024\n",
      "Absolute Error_Difference= 0.006492487965538363 Object Function: 2.9612426598054857\n",
      "Absolute Error_Difference= 0.006449812854301129 Object Function: 2.9547928469511846\n",
      "Absolute Error_Difference= 0.006407418246461738 Object Function: 2.948385428704723\n",
      "Absolute Error_Difference= 0.006365302298311448 Object Function: 2.9420201264064114\n",
      "Absolute Error_Difference= 0.006323463178223854 Object Function: 2.9356966632281876\n",
      "Absolute Error_Difference= 0.0062818990665651775 Object Function: 2.9294147641616224\n",
      "Absolute Error_Difference= 0.006240608155767546 Object Function: 2.923174156005855\n",
      "Absolute Error_Difference= 0.006199588650020349 Object Function: 2.9169745673558345\n",
      "Absolute Error_Difference= 0.0061588387654278876 Object Function: 2.9108157285904066\n",
      "Absolute Error_Difference= 0.0061183567297540264 Object Function: 2.9046973718606526\n",
      "Absolute Error_Difference= 0.0060781407823933264 Object Function: 2.8986192310782593\n",
      "Absolute Error_Difference= 0.006038189174397246 Object Function: 2.892581041903862\n",
      "Absolute Error_Difference= 0.005998500168258314 Object Function: 2.8865825417356037\n",
      "Absolute Error_Difference= 0.005959072037877711 Object Function: 2.880623469697726\n",
      "Absolute Error_Difference= 0.005919903068522636 Object Function: 2.8747035666292033\n",
      "Absolute Error_Difference= 0.0058809915567024085 Object Function: 2.868822575072501\n",
      "Absolute Error_Difference= 0.00584233581021687 Object Function: 2.862980239262284\n",
      "Absolute Error_Difference= 0.0058039341478721695 Object Function: 2.857176305114412\n",
      "Absolute Error_Difference= 0.005765784899568693 Object Function: 2.851410520214843\n",
      "Absolute Error_Difference= 0.00572788640619093 Object Function: 2.8456826338086523\n",
      "Absolute Error_Difference= 0.005690237019571498 Object Function: 2.8399923967890808\n",
      "Absolute Error_Difference= 0.005652835102308185 Object Function: 2.8343395616867726\n",
      "Absolute Error_Difference= 0.00561567902772353 Object Function: 2.828723882659049\n",
      "Absolute Error_Difference= 0.005578767179980737 Object Function: 2.8231451154790683\n",
      "Absolute Error_Difference= 0.005542097953769254 Object Function: 2.817603017525299\n",
      "Absolute Error_Difference= 0.005505669754267473 Object Function: 2.8120973477710316\n",
      "Absolute Error_Difference= 0.0054694809972635205 Object Function: 2.806627866773768\n",
      "Absolute Error_Difference= 0.005433530108909235 Object Function: 2.801194336664859\n",
      "Absolute Error_Difference= 0.0053978155256726446 Object Function: 2.795796521139186\n",
      "Absolute Error_Difference= 0.005362335694303777 Object Function: 2.7904341854448824\n",
      "Absolute Error_Difference= 0.005327089071813784 Object Function: 2.7851070963730686\n",
      "Absolute Error_Difference= 0.005292074125330615 Object Function: 2.779815022247738\n",
      "Absolute Error_Difference= 0.005257289331979109 Object Function: 2.774557732915759\n",
      "Absolute Error_Difference= 0.005222733179055972 Object Function: 2.769334999736703\n",
      "Absolute Error_Difference= 0.0051884041636260925 Object Function: 2.764146595573077\n",
      "Absolute Error_Difference= 0.005154300792767241 Object Function: 2.7589922947803096\n",
      "Absolute Error_Difference= 0.005120421583297841 Object Function: 2.7538718731970118\n",
      "Absolute Error_Difference= 0.005086765061819154 Object Function: 2.7487851081351926\n",
      "Absolute Error_Difference= 0.005053329764558523 Object Function: 2.743731778370634\n",
      "Absolute Error_Difference= 0.005020114237486162 Object Function: 2.738711664133148\n",
      "Absolute Error_Difference= 0.004987117035985644 Object Function: 2.7337245470971623\n",
      "Absolute Error_Difference= 0.004954336725046193 Object Function: 2.728770210372116\n",
      "Absolute Error_Difference= 0.004921771879024206 Object Function: 2.723848438493092\n",
      "Absolute Error_Difference= 0.004889421081649026 Object Function: 2.718959017411443\n",
      "Absolute Error_Difference= 0.004857282926057138 Object Function: 2.7141017344853857\n",
      "Absolute Error_Difference= 0.004825356014432014 Object Function: 2.7092763784709537\n",
      "Absolute Error_Difference= 0.004793638958398905 Object Function: 2.704482739512555\n",
      "Absolute Error_Difference= 0.004762130378497709 Object Function: 2.699720609134057\n",
      "Absolute Error_Difference= 0.004730828904402795 Object Function: 2.6949897802296543\n",
      "Absolute Error_Difference= 0.004699733174877263 Object Function: 2.690290047054777\n",
      "Absolute Error_Difference= 0.004668841837506488 Object Function: 2.6856212052172705\n",
      "Absolute Error_Difference= 0.00463815354883268 Object Function: 2.680983051668438\n",
      "Absolute Error_Difference= 0.004607666974258073 Object Function: 2.67637538469418\n",
      "Absolute Error_Difference= 0.004577380787829544 Object Function: 2.6717980039063502\n",
      "Absolute Error_Difference= 0.004547293672479302 Object Function: 2.667250710233871\n",
      "Absolute Error_Difference= 0.004517404319694052 Object Function: 2.662733305914177\n",
      "Absolute Error_Difference= 0.00448771142952431 Object Function: 2.6582455944846526\n",
      "Absolute Error_Difference= 0.004458213710711423 Object Function: 2.653787380773941\n",
      "Absolute Error_Difference= 0.004428909880312304 Object Function: 2.649358470893629\n",
      "Absolute Error_Difference= 0.004399798663982768 Object Function: 2.644958672229646\n",
      "Absolute Error_Difference= 0.004370878795574296 Object Function: 2.640587793434072\n",
      "Absolute Error_Difference= 0.004342149017423136 Object Function: 2.6362456444166487\n",
      "Absolute Error_Difference= 0.0043136080800527665 Object Function: 2.631932036336596\n",
      "Absolute Error_Difference= 0.004285254742234734 Object Function: 2.627646781594361\n",
      "Absolute Error_Difference= 0.004257087770793255 Object Function: 2.623389693823568\n",
      "Absolute Error_Difference= 0.0042291059408632314 Object Function: 2.6191605878827047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute Error_Difference= 0.004201308035421736 Object Function: 2.614959279847283\n",
      "Absolute Error_Difference= 0.0041736928455695654 Object Function: 2.6107855870017134\n",
      "Absolute Error_Difference= 0.0041462591703034235 Object Function: 2.60663932783141\n",
      "Absolute Error_Difference= 0.004119005816519916 Object Function: 2.60252032201489\n",
      "Absolute Error_Difference= 0.004091931598985354 Object Function: 2.5984283904159047\n",
      "Absolute Error_Difference= 0.004065035340259815 Object Function: 2.594363355075645\n",
      "Absolute Error_Difference= 0.004038315870564357 Object Function: 2.5903250392050805\n",
      "Absolute Error_Difference= 0.004011772027900928 Object Function: 2.5863132671771796\n",
      "Absolute Error_Difference= 0.0039854026578729496 Object Function: 2.5823278645193066\n",
      "Absolute Error_Difference= 0.003959206613638244 Object Function: 2.5783686579056684\n",
      "Absolute Error_Difference= 0.0039331827559907495 Object Function: 2.5744354751496776\n",
      "Absolute Error_Difference= 0.003907329953077632 Object Function: 2.5705281451966\n",
      "Absolute Error_Difference= 0.003881647080600903 Object Function: 2.566646498115999\n",
      "Absolute Error_Difference= 0.0038561330216229095 Object Function: 2.562790365094376\n",
      "Absolute Error_Difference= 0.0038307866664610835 Object Function: 2.558959578427915\n",
      "Absolute Error_Difference= 0.0038056069128935555 Object Function: 2.5551539715150215\n",
      "Absolute Error_Difference= 0.0037805926657550337 Object Function: 2.5513733788492665\n",
      "Absolute Error_Difference= 0.0037557428372521073 Object Function: 2.5476176360120144\n",
      "Absolute Error_Difference= 0.003731056346574224 Object Function: 2.54388657966544\n",
      "Absolute Error_Difference= 0.003706532120224093 Object Function: 2.540180047545216\n",
      "Absolute Error_Difference= 0.0036821690915207483 Object Function: 2.5364978784536953\n",
      "Absolute Error_Difference= 0.0036579662009619263 Object Function: 2.5328399122527334\n",
      "Absolute Error_Difference= 0.003633922395974043 Object Function: 2.5292059898567594\n",
      "Absolute Error_Difference= 0.0036100366308517984 Object Function: 2.5255959532259076\n",
      "Absolute Error_Difference= 0.0035863078668509907 Object Function: 2.5220096453590566\n",
      "Absolute Error_Difference= 0.0035627350719291684 Object Function: 2.5184469102871274\n",
      "Absolute Error_Difference= 0.003539317220988547 Object Function: 2.514907593066139\n",
      "Absolute Error_Difference= 0.0035160532954994217 Object Function: 2.5113915397706394\n",
      "Absolute Error_Difference= 0.003492942283755518 Object Function: 2.507898597486884\n",
      "Absolute Error_Difference= 0.0034699831806710435 Object Function: 2.504428614306213\n",
      "Absolute Error_Difference= 0.0034471749877078572 Object Function: 2.500981439318505\n",
      "Absolute Error_Difference= 0.0034245167129740572 Object Function: 2.497556922605531\n",
      "Absolute Error_Difference= 0.0034020073710232523 Object Function: 2.4941549152345077\n",
      "Absolute Error_Difference= 0.0033796459829202874 Object Function: 2.4907752692515874\n",
      "Absolute Error_Difference= 0.0033574315762257 Object Function: 2.4874178376753617\n",
      "Absolute Error_Difference= 0.0033353631847239384 Object Function: 2.484082474490638\n",
      "Absolute Error_Difference= 0.0033134398487613126 Object Function: 2.4807690346418765\n",
      "Absolute Error_Difference= 0.0032916606148316596 Object Function: 2.477477374027045\n",
      "Absolute Error_Difference= 0.0032700245357792923 Object Function: 2.4742073494912655\n",
      "Absolute Error_Difference= 0.0032485306705902772 Object Function: 2.4709588188206753\n",
      "Absolute Error_Difference= 0.0032271780846206966 Object Function: 2.4677316407360546\n",
      "Absolute Error_Difference= 0.003205965849063297 Object Function: 2.4645256748869913\n",
      "Absolute Error_Difference= 0.0031848930415483423 Object Function: 2.461340781845443\n",
      "Absolute Error_Difference= 0.003163958745552531 Object Function: 2.4581768230998904\n",
      "Absolute Error_Difference= 0.0031431620506126023 Object Function: 2.455033661049278\n",
      "Absolute Error_Difference= 0.0031225020523497626 Object Function: 2.451911158996928\n",
      "Absolute Error_Difference= 0.003101977852195237 Object Function: 2.448809181144733\n",
      "Absolute Error_Difference= 0.0030815885575807833 Object Function: 2.445727592587152\n",
      "Absolute Error_Difference= 0.0030613332817703842 Object Function: 2.4426662593053816\n",
      "Absolute Error_Difference= 0.0030412111438122835 Object Function: 2.4396250481615693\n",
      "Absolute Error_Difference= 0.003021221268658447 Object Function: 2.436603826892911\n",
      "Absolute Error_Difference= 0.003001362786905659 Object Function: 2.4336024641060052\n",
      "Absolute Error_Difference= 0.002981634834939406 Object Function: 2.430620829271066\n",
      "Absolute Error_Difference= 0.0029620365547384786 Object Function: 2.4276587927163273\n",
      "Absolute Error_Difference= 0.002942567093997539 Object Function: 2.42471622562233\n",
      "Absolute Error_Difference= 0.0029232256059885664 Object Function: 2.4217930000163412\n",
      "Absolute Error_Difference= 0.00290401124957107 Object Function: 2.41888898876677\n",
      "Absolute Error_Difference= 0.0028849231890450966 Object Function: 2.416004065577725\n",
      "Absolute Error_Difference= 0.002865960594320871 Object Function: 2.413138104983404\n",
      "Absolute Error_Difference= 0.0028471226406843186 Object Function: 2.41029098234272\n",
      "Absolute Error_Difference= 0.0028284085089063105 Object Function: 2.4074625738338136\n",
      "Absolute Error_Difference= 0.00280981738505659 Object Function: 2.404652756448757\n",
      "Absolute Error_Difference= 0.002791348460648102 Object Function: 2.401861407988109\n",
      "Absolute Error_Difference= 0.0027730009324495875 Object Function: 2.3990884070556593\n",
      "Absolute Error_Difference= 0.002754774002506899 Object Function: 2.3963336330531524\n",
      "Absolute Error_Difference= 0.0027366668781194647 Object Function: 2.393596966175033\n",
      "Absolute Error_Difference= 0.0027186787718651573 Object Function: 2.3908782874031678\n",
      "Absolute Error_Difference= 0.002700808901363594 Object Function: 2.388177478501804\n",
      "Absolute Error_Difference= 0.002683056489531488 Object Function: 2.3854944220122727\n",
      "Absolute Error_Difference= 0.002665420764248694 Object Function: 2.382829001248024\n",
      "Absolute Error_Difference= 0.0026479009585149704 Object Function: 2.380181100289509\n",
      "Absolute Error_Difference= 0.0026304963104899493 Object Function: 2.377550603979019\n",
      "Absolute Error_Difference= 0.0026132060631498533 Object Function: 2.374937397915869\n",
      "Absolute Error_Difference= 0.0025960294646147908 Object Function: 2.3723413684512544\n",
      "Absolute Error_Difference= 0.0025789657677752764 Object Function: 2.369762402683479\n",
      "Absolute Error_Difference= 0.002562014230615084 Object Function: 2.367200388452864\n",
      "Absolute Error_Difference= 0.002545174115866633 Object Function: 2.3646552143369974\n",
      "Absolute Error_Difference= 0.002528444691158871 Object Function: 2.3621267696458386\n",
      "Absolute Error_Difference= 0.002511825228928899 Object Function: 2.3596149444169097\n",
      "Absolute Error_Difference= 0.0024953150064184193 Object Function: 2.3571196294104912\n",
      "Absolute Error_Difference= 0.0024789133055400647 Object Function: 2.354640716104951\n",
      "Absolute Error_Difference= 0.002462619413019951 Object Function: 2.3521780966919312\n",
      "Absolute Error_Difference= 0.0024464326202204845 Object Function: 2.3497316640717107\n",
      "Absolute Error_Difference= 0.0024303522231861052 Object Function: 2.3473013118485246\n",
      "Absolute Error_Difference= 0.0024143775225695663 Object Function: 2.344886934325955\n",
      "Absolute Error_Difference= 0.0023985078236252733 Object Function: 2.34248842650233\n",
      "Absolute Error_Difference= 0.0023827424361870797 Object Function: 2.3401056840661427\n",
      "Absolute Error_Difference= 0.0023670806746109996 Object Function: 2.3377386033915317\n",
      "Absolute Error_Difference= 0.0023515218577871977 Object Function: 2.3353870815337445\n",
      "Absolute Error_Difference= 0.002336065308982782 Object Function: 2.3330510162247617\n",
      "Absolute Error_Difference= 0.0023207103560864972 Object Function: 2.3307303058686752\n",
      "Absolute Error_Difference= 0.002305456331270772 Object Function: 2.3284248495374045\n",
      "Absolute Error_Difference= 0.002290302571100966 Object Function: 2.3261345469663035\n",
      "Absolute Error_Difference= 0.00227524841657889 Object Function: 2.3238592985497246\n",
      "Absolute Error_Difference= 0.0022602932130095787 Object Function: 2.321599005336715\n",
      "Absolute Error_Difference= 0.0022454363099604358 Object Function: 2.3193535690267546\n",
      "Absolute Error_Difference= 0.0022306770612803284 Object Function: 2.3171228919654743\n",
      "Absolute Error_Difference= 0.0022160148251169076 Object Function: 2.3149068771403574\n",
      "Absolute Error_Difference= 0.0022014489638255696 Object Function: 2.312705428176532\n",
      "Absolute Error_Difference= 0.0021869788438966253 Object Function: 2.310518449332635\n",
      "Absolute Error_Difference= 0.0021726038360565525 Object Function: 2.3083458454965786\n",
      "Absolute Error_Difference= 0.0021583233151121206 Object Function: 2.3061875221814665\n",
      "Absolute Error_Difference= 0.002144136659986806 Object Function: 2.3040433855214797\n",
      "Absolute Error_Difference= 0.0021300432537350034 Object Function: 2.3019133422677447\n",
      "Absolute Error_Difference= 0.0021160424834221203 Object Function: 2.2997972997843226\n",
      "Absolute Error_Difference= 0.002102133740115697 Object Function: 2.297695166044207\n",
      "Absolute Error_Difference= 0.002088316419003533 Object Function: 2.2956068496252033\n",
      "Absolute Error_Difference= 0.0020745899190641737 Object Function: 2.293532259706139\n",
      "Absolute Error_Difference= 0.0020609536434141873 Object Function: 2.291471306062725\n",
      "Absolute Error_Difference= 0.002047406998972434 Object Function: 2.2894238990637525\n",
      "Absolute Error_Difference= 0.002033949396592405 Object Function: 2.28738994966716\n",
      "Absolute Error_Difference= 0.002020580251029358 Object Function: 2.285369369416131\n",
      "Absolute Error_Difference= 0.0020072989807946584 Object Function: 2.283362070435336\n",
      "Absolute Error_Difference= 0.001994105008357838 Object Function: 2.2813679654269783\n",
      "Absolute Error_Difference= 0.001980997759875258 Object Function: 2.279386967667103\n",
      "Absolute Error_Difference= 0.0019679766652949127 Object Function: 2.277418991001808\n",
      "Absolute Error_Difference= 0.0019550411583559857 Object Function: 2.275463949843452\n",
      "Absolute Error_Difference= 0.0019421906765035857 Object Function: 2.2735217591669485\n",
      "Absolute Error_Difference= 0.0019294246607821641 Object Function: 2.2715923345061664\n",
      "Absolute Error_Difference= 0.0019167425561192886 Object Function: 2.269675591950047\n",
      "Absolute Error_Difference= 0.001904143810865122 Object Function: 2.267771448139182\n",
      "Absolute Error_Difference= 0.0018916278771654582 Object Function: 2.2658798202620165\n",
      "Absolute Error_Difference= 0.0018791942106854975 Object Function: 2.264000626051331\n",
      "Absolute Error_Difference= 0.001866842270632496 Object Function: 2.2621337837806985\n",
      "Absolute Error_Difference= 0.001854571519897874 Object Function: 2.2602792122608006\n",
      "Absolute Error_Difference= 0.0018423814247561232 Object Function: 2.2584368308360445\n",
      "Absolute Error_Difference= 0.0018302714550935129 Object Function: 2.256606559380951\n",
      "Absolute Error_Difference= 0.0018182410842428887 Object Function: 2.254788318296708\n",
      "Absolute Error_Difference= 0.0018062897890032126 Object Function: 2.252982028507705\n",
      "Absolute Error_Difference= 0.0017944170496018153 Object Function: 2.251187611458103\n",
      "Absolute Error_Difference= 0.0017826223496748561 Object Function: 2.2494049891084282\n",
      "Absolute Error_Difference= 0.001770905176325055 Object Function: 2.247634083932103\n",
      "Absolute Error_Difference= 0.0017592650198938742 Object Function: 2.2458748189122093\n",
      "Absolute Error_Difference= 0.001747701374221311 Object Function: 2.244127117537988\n",
      "Absolute Error_Difference= 0.0017362137363470254 Object Function: 2.242390903801641\n",
      "Absolute Error_Difference= 0.00172480160673949 Object Function: 2.2406661021949015\n",
      "Absolute Error_Difference= 0.0017134644889669204 Object Function: 2.2389526377059346\n",
      "Absolute Error_Difference= 0.0017022018901005076 Object Function: 2.237250435815834\n",
      "Absolute Error_Difference= 0.0016910133202574507 Object Function: 2.2355594224955766\n",
      "Absolute Error_Difference= 0.0016798982928647455 Object Function: 2.233879524202712\n",
      "Absolute Error_Difference= 0.0016688563245370602 Object Function: 2.232210667878175\n",
      "Absolute Error_Difference= 0.0016578869350150072 Object Function: 2.23055278094316\n",
      "Absolute Error_Difference= 0.0016469896473245704 Object Function: 2.228905791295835\n",
      "Absolute Error_Difference= 0.0016361639874444833 Object Function: 2.2272696273083907\n",
      "Absolute Error_Difference= 0.001625409484597995 Object Function: 2.2256442178237927\n",
      "Absolute Error_Difference= 0.0016147256711169788 Object Function: 2.2240294921526758\n",
      "Absolute Error_Difference= 0.0016041120822887223 Object Function: 2.222425380070387\n",
      "Absolute Error_Difference= 0.0015935682565775267 Object Function: 2.2208318118138095\n",
      "Absolute Error_Difference= 0.0015830937353880081 Object Function: 2.2192487180784215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute Error_Difference= 0.0015726880632547235 Object Function: 2.2176760300151668\n",
      "Absolute Error_Difference= 0.0015623507875375253 Object Function: 2.2161136792276293\n",
      "Absolute Error_Difference= 0.0015520814587501874 Object Function: 2.214561597768879\n",
      "Absolute Error_Difference= 0.0015418796302109072 Object Function: 2.213019718138668\n",
      "Absolute Error_Difference= 0.0015317448582901072 Object Function: 2.211487973280378\n",
      "Absolute Error_Difference= 0.0015216767022057098 Object Function: 2.2099662965781723\n",
      "Absolute Error_Difference= 0.0015116747240866424 Object Function: 2.2084546218540857\n",
      "Absolute Error_Difference= 0.0015017384889568497 Object Function: 2.206952883365129\n",
      "Absolute Error_Difference= 0.0014918675646726776 Object Function: 2.205461015800456\n",
      "Absolute Error_Difference= 0.0014820615219646172 Object Function: 2.2039789542784916\n",
      "Absolute Error_Difference= 0.0014723199343302795 Object Function: 2.2025066343441613\n",
      "Absolute Error_Difference= 0.0014626423781840536 Object Function: 2.201043991965977\n",
      "Absolute Error_Difference= 0.001453028432556902 Object Function: 2.1995909635334203\n",
      "Absolute Error_Difference= 0.0014434776793863513 Object Function: 2.198147485854034\n",
      "Absolute Error_Difference= 0.0014339897033224247 Object Function: 2.1967134961507115\n",
      "Absolute Error_Difference= 0.0014245640916557 Object Function: 2.195288932059056\n",
      "Absolute Error_Difference= 0.0014152004345668878 Object Function: 2.193873731624489\n",
      "Absolute Error_Difference= 0.001405898324734256 Object Function: 2.1924678332997547\n",
      "Absolute Error_Difference= 0.00139665735768979 Object Function: 2.191071175942065\n",
      "Absolute Error_Difference= 0.0013874771315052215 Object Function: 2.1896836988105597\n",
      "Absolute Error_Difference= 0.0013783572468910599 Object Function: 2.1883053415636686\n",
      "Absolute Error_Difference= 0.0013692973072951808 Object Function: 2.1869360442563734\n",
      "Absolute Error_Difference= 0.0013602969186412572 Object Function: 2.185575747337732\n",
      "Absolute Error_Difference= 0.0013513556895454748 Object Function: 2.1842243916481867\n",
      "Absolute Error_Difference= 0.0013424732311553278 Object Function: 2.1828819184170314\n",
      "Absolute Error_Difference= 0.0013336491570878906 Object Function: 2.1815482692599435\n",
      "Absolute Error_Difference= 0.0013248830836705139 Object Function: 2.180223386176273\n",
      "Absolute Error_Difference= 0.0013161746296632693 Object Function: 2.1789072115466097\n",
      "Absolute Error_Difference= 0.0013075234162664984 Object Function: 2.177599688130343\n",
      "Absolute Error_Difference= 0.001298929067304666 Object Function: 2.1763007590630385\n",
      "Absolute Error_Difference= 0.0012903912089781144 Object Function: 2.1750103678540604\n",
      "Absolute Error_Difference= 0.0012819094699594302 Object Function: 2.173728458384101\n",
      "Absolute Error_Difference= 0.0012734834814205342 Object Function: 2.1724549749026805\n",
      "Absolute Error_Difference= 0.001265112876891461 Object Function: 2.171189862025789\n",
      "Absolute Error_Difference= 0.0012567972922941095 Object Function: 2.169933064733495\n",
      "Absolute Error_Difference= 0.0012485363660523774 Object Function: 2.1686845283674425\n",
      "Absolute Error_Difference= 0.0012403297388678958 Object Function: 2.1674441986285746\n",
      "Absolute Error_Difference= 0.0012321770537915278 Object Function: 2.166212021574783\n",
      "Absolute Error_Difference= 0.001224077956346381 Object Function: 2.1649879436184367\n",
      "Absolute Error_Difference= 0.0012160320941978497 Object Function: 2.163771911524239\n",
      "Absolute Error_Difference= 0.0012080391175368632 Object Function: 2.162563872406702\n",
      "Absolute Error_Difference= 0.0012000986786899759 Object Function: 2.161363773728012\n",
      "Absolute Error_Difference= 0.0011922104323036642 Object Function: 2.1601715632957084\n",
      "Absolute Error_Difference= 0.0011843740353549848 Object Function: 2.1589871892603534\n",
      "Absolute Error_Difference= 0.0011765891470543188 Object Function: 2.157810600113299\n",
      "Absolute Error_Difference= 0.0011688554287720976 Object Function: 2.156641744684527\n",
      "Absolute Error_Difference= 0.0011611725442404186 Object Function: 2.1554805721402865\n",
      "Absolute Error_Difference= 0.0011535401592719374 Object Function: 2.1543270319810146\n",
      "Absolute Error_Difference= 0.001145957941961484 Object Function: 2.153181074039053\n",
      "Absolute Error_Difference= 0.0011384255625563888 Object Function: 2.1520426484764967\n",
      "Absolute Error_Difference= 0.001130942693458259 Object Function: 2.1509117057830385\n",
      "Absolute Error_Difference= 0.0011235090092598377 Object Function: 2.1497881967737786\n",
      "Absolute Error_Difference= 0.0011161241866450844 Object Function: 2.1486720725871336\n",
      "Absolute Error_Difference= 0.0011087879044318072 Object Function: 2.1475632846827017\n",
      "Absolute Error_Difference= 0.0011014998436267298 Object Function: 2.146461784839075\n",
      "Absolute Error_Difference= 0.001094259687222987 Object Function: 2.145367525151852\n",
      "Absolute Error_Difference= 0.001087067120325802 Object Function: 2.1442804580315262\n",
      "Absolute Error_Difference= 0.0010799218301857927 Object Function: 2.1432005362013404\n",
      "Absolute Error_Difference= 0.0010728235060155633 Object Function: 2.142127712695325\n",
      "Absolute Error_Difference= 0.0010657718391224869 Object Function: 2.1410619408562024\n",
      "Absolute Error_Difference= 0.0010587665228105614 Object Function: 2.140003174333392\n",
      "Absolute Error_Difference= 0.001051807252435033 Object Function: 2.138951367080957\n",
      "Absolute Error_Difference= 0.0010448937253433321 Object Function: 2.1379064733556135\n",
      "Absolute Error_Difference= 0.001038025640828888 Object Function: 2.1368684477147846\n",
      "Absolute Error_Difference= 0.0010312027002399304 Object Function: 2.1358372450145446\n",
      "Absolute Error_Difference= 0.001024424606823171 Object Function: 2.1348128204077215\n",
      "Absolute Error_Difference= 0.0010176910658001859 Object Function: 2.1337951293419213\n",
      "Absolute Error_Difference= 0.0010110017843230068 Object Function: 2.1327841275575983\n",
      "Absolute Error_Difference= 0.0010043564714852238 Object Function: 2.131779771086113\n",
      "Absolute Error_Difference= 0.0009977548382797963 Object Function: 2.1307820162478333\n",
      "Absolute Error_Difference= 0.0009911965975795134 Object Function: 2.1297908196502537\n",
      "Absolute Error_Difference= 0.0009846814642049395 Object Function: 2.128806138186049\n",
      "Absolute Error_Difference= 0.0009782091547854144 Object Function: 2.1278279290312634\n",
      "Absolute Error_Difference= 0.0009717793878598613 Object Function: 2.1268561496434035\n",
      "Absolute Error_Difference= 0.0009653918837355668 Object Function: 2.125890757759668\n",
      "Absolute Error_Difference= 0.0009590463647013436 Object Function: 2.1249317113949666\n",
      "Absolute Error_Difference= 0.0009527425547339874 Object Function: 2.1239789688402326\n",
      "Absolute Error_Difference= 0.0009464801797101074 Object Function: 2.1230324886605225\n",
      "Absolute Error_Difference= 0.0009402589672449224 Object Function: 2.1220922296932776\n",
      "Absolute Error_Difference= 0.0009340786468241546 Object Function: 2.1211581510464534\n",
      "Absolute Error_Difference= 0.0009279389496263946 Object Function: 2.120230212096827\n",
      "Absolute Error_Difference= 0.0009218396086514424 Object Function: 2.1193083724881756\n",
      "Absolute Error_Difference= 0.000915780358619056 Object Function: 2.1183925921295566\n",
      "Absolute Error_Difference= 0.0009097609360297909 Object Function: 2.1174828311935268\n",
      "Absolute Error_Difference= 0.000903781079129029 Object Function: 2.1165790501143977\n",
      "Absolute Error_Difference= 0.0008978405277493273 Object Function: 2.1156812095866484\n",
      "Absolute Error_Difference= 0.0008919390236559188 Object Function: 2.1147892705629925\n",
      "Absolute Error_Difference= 0.0008860763101274927 Object Function: 2.113903194252865\n",
      "Absolute Error_Difference= 0.0008802521321782386 Object Function: 2.1130229421206868\n",
      "Absolute Error_Difference= 0.0008744662365800515 Object Function: 2.1121484758841067\n",
      "Absolute Error_Difference= 0.0008687183716293845 Object Function: 2.1112797575124773\n",
      "Absolute Error_Difference= 0.0008630082874203637 Object Function: 2.110416749225057\n",
      "Absolute Error_Difference= 0.0008573357355321498 Object Function: 2.109559413489525\n",
      "Absolute Error_Difference= 0.000851700469369554 Object Function: 2.1087077130201552\n",
      "Absolute Error_Difference= 0.0008461022437646903 Object Function: 2.1078616107763906\n",
      "Absolute Error_Difference= 0.0008405408152936111 Object Function: 2.107021069961097\n",
      "Absolute Error_Difference= 0.0008350159420906778 Object Function: 2.1061860540190063\n",
      "Absolute Error_Difference= 0.0008295273838596628 Object Function: 2.1053565266351466\n",
      "Absolute Error_Difference= 0.0008240749019452487 Object Function: 2.1045324517332014\n",
      "Absolute Error_Difference= 0.0008186582591220848 Object Function: 2.1037137934740793\n",
      "Absolute Error_Difference= 0.000813277219938513 Object Function: 2.1029005162541408\n",
      "Absolute Error_Difference= 0.0008079315502902418 Object Function: 2.1020925847038505\n",
      "Absolute Error_Difference= 0.0008026210177232151 Object Function: 2.1012899636861273\n",
      "Absolute Error_Difference= 0.0007973453912493156 Object Function: 2.100492618294878\n",
      "Absolute Error_Difference= 0.0007921044415160061 Object Function: 2.099700513853362\n",
      "Absolute Error_Difference= 0.0007868979404852539 Object Function: 2.0989136159128767\n",
      "Absolute Error_Difference= 0.0007817256618114499 Object Function: 2.0981318902510653\n",
      "Absolute Error_Difference= 0.000776587380496796 Object Function: 2.0973553028705685\n",
      "Absolute Error_Difference= 0.0007714828730787104 Object Function: 2.0965838199974898\n",
      "Absolute Error_Difference= 0.0007664119176098438 Object Function: 2.09581740807988\n",
      "Absolute Error_Difference= 0.0007613742935044243 Object Function: 2.0950560337863755\n",
      "Absolute Error_Difference= 0.0007563697817034587 Object Function: 2.094299664004672\n",
      "Absolute Error_Difference= 0.0007513981645357326 Object Function: 2.0935482658401363\n",
      "Absolute Error_Difference= 0.0007464592257977465 Object Function: 2.0928018066143386\n",
      "Absolute Error_Difference= 0.0007415527507186326 Object Function: 2.09206025386362\n",
      "Absolute Error_Difference= 0.0007366785258682285 Object Function: 2.0913235753377517\n",
      "Absolute Error_Difference= 0.0007318363393116201 Object Function: 2.09059173899844\n",
      "Absolute Error_Difference= 0.000727025980401308 Object Function: 2.0898647130180388\n",
      "Absolute Error_Difference= 0.0007222472400019164 Object Function: 2.089142465778037\n",
      "Absolute Error_Difference= 0.0007174999102521618 Object Function: 2.0884249658677847\n",
      "Absolute Error_Difference= 0.000712783784668769 Object Function: 2.087712182083116\n",
      "Absolute Error_Difference= 0.0007080986581788906 Object Function: 2.087004083424937\n",
      "Absolute Error_Difference= 0.000703444327043723 Object Function: 2.0863006390978933\n",
      "Absolute Error_Difference= 0.0006988205887945576 Object Function: 2.0856018185090988\n",
      "Absolute Error_Difference= 0.0006942272423624551 Object Function: 2.0849075912667363\n",
      "Absolute Error_Difference= 0.0006896640880080795 Object Function: 2.0842179271787282\n",
      "Absolute Error_Difference= 0.0006851309272346562 Object Function: 2.0835327962514936\n",
      "Absolute Error_Difference= 0.0006806275629247516 Object Function: 2.082852168688569\n",
      "Absolute Error_Difference= 0.0006761537992496791 Object Function: 2.082176014889319\n",
      "Absolute Error_Difference= 0.0006717094415864544 Object Function: 2.0815043054477327\n",
      "Absolute Error_Difference= 0.0006672942966852169 Object Function: 2.0808370111510475\n",
      "Absolute Error_Difference= 0.0006629081724938146 Object Function: 2.0801741029785537\n",
      "Absolute Error_Difference= 0.0006585508783434335 Object Function: 2.07951555210021\n",
      "Absolute Error_Difference= 0.0006542222246395113 Object Function: 2.0788613298755707\n",
      "Absolute Error_Difference= 0.0006499220232023539 Object Function: 2.0782114078523684\n",
      "Absolute Error_Difference= 0.0006456500869411741 Object Function: 2.077565757765427\n",
      "Absolute Error_Difference= 0.0006414062301254297 Object Function: 2.0769243515353017\n",
      "Absolute Error_Difference= 0.0006371902681814312 Object Function: 2.0762871612671203\n",
      "Absolute Error_Difference= 0.0006330020177327533 Object Function: 2.0756541592493876\n",
      "Absolute Error_Difference= 0.000628841296662408 Object Function: 2.075025317952725\n",
      "Absolute Error_Difference= 0.0006247079239964926 Object Function: 2.0744006100287287\n",
      "Absolute Error_Difference= 0.0006206017199614777 Object Function: 2.073780008308767\n",
      "Absolute Error_Difference= 0.0006165225060383861 Object Function: 2.073163485802729\n",
      "Absolute Error_Difference= 0.000612470104757179 Object Function: 2.0725510156979716\n",
      "Absolute Error_Difference= 0.0006084443398970407 Object Function: 2.0719425713580746\n",
      "Absolute Error_Difference= 0.0006044450364006693 Object Function: 2.071338126321674\n",
      "Absolute Error_Difference= 0.0006004720202885672 Object Function: 2.0707376543013853\n",
      "Absolute Error_Difference= 0.0005965251188353449 Object Function: 2.07014112918255\n",
      "Absolute Error_Difference= 0.0005926041603490084 Object Function: 2.069548525022201\n",
      "Absolute Error_Difference= 0.0005887089743024099 Object Function: 2.0689598160478986\n",
      "Absolute Error_Difference= 0.000584839391316816 Object Function: 2.0683749766565818\n",
      "Absolute Error_Difference= 0.0005809952430939624 Object Function: 2.067793981413488\n",
      "Absolute Error_Difference= 0.0005771763624475845 Object Function: 2.06721680505104\n",
      "Absolute Error_Difference= 0.0005733825833060813 Object Function: 2.066643422467734\n",
      "Absolute Error_Difference= 0.0005696137406356883 Object Function: 2.0660738087270984\n",
      "Absolute Error_Difference= 0.0005658696706025701 Object Function: 2.065507939056496\n",
      "Absolute Error_Difference= 0.0005621502103121401 Object Function: 2.0649457888461837\n",
      "Absolute Error_Difference= 0.0005584551980275521 Object Function: 2.064387333648156\n",
      "Absolute Error_Difference= 0.0005547844730555695 Object Function: 2.0638325491751006\n",
      "Absolute Error_Difference= 0.0005511378757598884 Object Function: 2.0632814112993407\n",
      "Absolute Error_Difference= 0.0005475152475185041 Object Function: 2.0627338960518222\n",
      "Absolute Error_Difference= 0.0005439164308369548 Object Function: 2.0621899796209853\n",
      "Absolute Error_Difference= 0.0005403412691449283 Object Function: 2.0616496383518403\n",
      "Absolute Error_Difference= 0.0005367896069907729 Object Function: 2.0611128487448496\n",
      "Absolute Error_Difference= 0.0005332612899096034 Object Function: 2.06057958745494\n",
      "Absolute Error_Difference= 0.0005297561644637128 Object Function: 2.0600498312904763\n",
      "Absolute Error_Difference= 0.0005262740781679653 Object Function: 2.0595235572123083\n",
      "Absolute Error_Difference= 0.0005228148796452281 Object Function: 2.059000742332663\n",
      "Absolute Error_Difference= 0.0005193784184149841 Object Function: 2.058481363914248\n",
      "Absolute Error_Difference= 0.0005159645450363293 Object Function: 2.0579653993692117\n",
      "Absolute Error_Difference= 0.0005125731110497966 Object Function: 2.057452826258162\n",
      "Absolute Error_Difference= 0.000509203968980021 Object Function: 2.056943622289182\n",
      "Absolute Error_Difference= 0.0005058569722122819 Object Function: 2.0564377653169696\n",
      "Absolute Error_Difference= 0.0005025319752740565 Object Function: 2.0559352333416956\n",
      "Absolute Error_Difference= 0.0004992288335512463 Object Function: 2.0554360045081443\n",
      "Absolute Error_Difference= 0.0004959474033774391 Object Function: 2.054940057104767\n",
      "Absolute Error_Difference= 0.0004926875420099286 Object Function: 2.054447369562757\n",
      "Absolute Error_Difference= 0.0004894491077220842 Object Function: 2.053957920455035\n",
      "Absolute Error_Difference= 0.00048623195964170307 Object Function: 2.053471688495393\n",
      "Absolute Error_Difference= 0.000483035957889566 Object Function: 2.0529886525375036\n",
      "Absolute Error_Difference= 0.0004798609634337758 Object Function: 2.05250879157407\n",
      "Absolute Error_Difference= 0.00047670683821365856 Object Function: 2.052032084735856\n",
      "Absolute Error_Difference= 0.00047357344507537036 Object Function: 2.051558511290781\n",
      "Absolute Error_Difference= 0.0004704606477075046 Object Function: 2.0510880506430733\n",
      "Absolute Error_Difference= 0.00046736831074811747 Object Function: 2.050620682332325\n",
      "Absolute Error_Difference= 0.0004642962997003508 Object Function: 2.050156386032625\n",
      "Absolute Error_Difference= 0.0004612444809861671 Object Function: 2.0496951415516387\n",
      "Absolute Error_Difference= 0.0004582127218890619 Object Function: 2.0492369288297496\n",
      "Absolute Error_Difference= 0.0004552008905318594 Object Function: 2.0487817279392178\n",
      "Absolute Error_Difference= 0.00045220885592467397 Object Function: 2.048329519083293\n",
      "Absolute Error_Difference= 0.0004492364879733479 Object Function: 2.0478802825953197\n",
      "Absolute Error_Difference= 0.0004462836573440043 Object Function: 2.0474339989379757\n",
      "Absolute Error_Difference= 0.00044335023571884236 Object Function: 2.046990648702257\n",
      "Absolute Error_Difference= 0.0004404360954595177 Object Function: 2.0465502126067974\n",
      "Absolute Error_Difference= 0.0004375411098136439 Object Function: 2.0461126714969837\n",
      "Absolute Error_Difference= 0.0004346651529272272 Object Function: 2.0456780063440565\n",
      "Absolute Error_Difference= 0.00043180809968523803 Object Function: 2.0452461982443713\n",
      "Absolute Error_Difference= 0.0004289698258457264 Object Function: 2.0448172284185255\n",
      "Absolute Error_Difference= 0.00042615020799319225 Object Function: 2.0443910782105323\n",
      "Absolute Error_Difference= 0.0004233491234706399 Object Function: 2.0439677290870617\n",
      "Absolute Error_Difference= 0.00042056645047106045 Object Function: 2.0435471626365906\n",
      "Absolute Error_Difference= 0.0004178020679668215 Object Function: 2.043129360568624\n",
      "Absolute Error_Difference= 0.00041505585579004745 Object Function: 2.0427143047128338\n",
      "Absolute Error_Difference= 0.00041232769439725203 Object Function: 2.0423019770184365\n",
      "Absolute Error_Difference= 0.00040961746525791654 Object Function: 2.0418923595531786\n",
      "Absolute Error_Difference= 0.0004069250503904165 Object Function: 2.041485434502788\n",
      "Absolute Error_Difference= 0.00040425033280744316 Object Function: 2.0410811841699807\n",
      "Absolute Error_Difference= 0.0004015931961554031 Object Function: 2.0406795909738253\n",
      "Absolute Error_Difference= 0.00039895352479346613 Object Function: 2.040280637449032\n",
      "Absolute Error_Difference= 0.0003963312040342615 Object Function: 2.0398843062449976\n",
      "Absolute Error_Difference= 0.0003937261197610731 Object Function: 2.0394905801252365\n",
      "Absolute Error_Difference= 0.00039113815873026425 Object Function: 2.0390994419665063\n",
      "Absolute Error_Difference= 0.0003885672083270286 Object Function: 2.0387108747581792\n",
      "Absolute Error_Difference= 0.0003860131568194092 Object Function: 2.03832486160136\n",
      "Absolute Error_Difference= 0.0003834758930438831 Object Function: 2.037941385708316\n",
      "Absolute Error_Difference= 0.0003809553066962401 Object Function: 2.0375604304016197\n",
      "Absolute Error_Difference= 0.00037845128821079044 Object Function: 2.037181979113409\n",
      "Absolute Error_Difference= 0.0003759637285889461 Object Function: 2.03680601538482\n",
      "Absolute Error_Difference= 0.00037349251970697495 Object Function: 2.036432522865113\n",
      "Absolute Error_Difference= 0.00037103755406331373 Object Function: 2.0360614853110497\n",
      "Absolute Error_Difference= 0.00036859872493044676 Object Function: 2.0356928865861192\n",
      "Absolute Error_Difference= 0.0003661759261950337 Object Function: 2.035326710659924\n",
      "Absolute Error_Difference= 0.00036376905250712355 Object Function: 2.034962941607417\n",
      "Absolute Error_Difference= 0.00036137799921931446 Object Function: 2.0346015636081978\n",
      "Absolute Error_Difference= 0.0003590026623010445 Object Function: 2.0342425609458967\n",
      "Absolute Error_Difference= 0.00035664293846027206 Object Function: 2.0338859180074365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute Error_Difference= 0.00035429872512215965 Object Function: 2.0335316192823143\n",
      "Absolute Error_Difference= 0.00035196992023101004 Object Function: 2.0331796493620833\n",
      "Absolute Error_Difference= 0.0003496564226241894 Object Function: 2.032829992939459\n",
      "Absolute Error_Difference= 0.0003473581316066898 Object Function: 2.0324826348078524\n",
      "Absolute Error_Difference= 0.00034507494726554455 Object Function: 2.032137559860587\n",
      "Absolute Error_Difference= 0.00034280677027753725 Object Function: 2.0317947530903093\n",
      "Absolute Error_Difference= 0.0003405535020104544 Object Function: 2.031454199588299\n",
      "Absolute Error_Difference= 0.00033831504448311733 Object Function: 2.0311158845438158\n",
      "Absolute Error_Difference= 0.0003360913003338517 Object Function: 2.030779793243482\n",
      "Absolute Error_Difference= 0.00033388217284402444 Object Function: 2.030445911070638\n",
      "Absolute Error_Difference= 0.00033168756593937587 Object Function: 2.0301142235046985\n",
      "Absolute Error_Difference= 0.00032950738419534886 Object Function: 2.029784716120503\n",
      "Absolute Error_Difference= 0.0003273415327695872 Object Function: 2.0294573745877336\n",
      "Absolute Error_Difference= 0.00032518991749830306 Object Function: 2.0291321846702353\n",
      "Absolute Error_Difference= 0.0003230524447692673 Object Function: 2.028809132225466\n",
      "Absolute Error_Difference= 0.0003209290216457106 Object Function: 2.0284882032038203\n",
      "Absolute Error_Difference= 0.0003188195558161411 Object Function: 2.028169383648004\n",
      "Absolute Error_Difference= 0.0003167239554433543 Object Function: 2.027852659692561\n",
      "Absolute Error_Difference= 0.00031464212948861814 Object Function: 2.027538017563072\n",
      "Absolute Error_Difference= 0.00031257398735595743 Object Function: 2.027225443575716\n",
      "Absolute Error_Difference= 0.0003105194391204158 Object Function: 2.026914924136596\n",
      "Absolute Error_Difference= 0.00030847839543879374 Object Function: 2.026606445741157\n",
      "Absolute Error_Difference= 0.0003064507675101247 Object Function: 2.026299994973647\n",
      "Absolute Error_Difference= 0.00030443646719513495 Object Function: 2.0259955585064517\n",
      "Absolute Error_Difference= 0.00030243540687502346 Object Function: 2.0256931230995767\n",
      "Absolute Error_Difference= 0.000300447499498091 Object Function: 2.0253926756000786\n",
      "Absolute Error_Difference= 0.00029847265863836014 Object Function: 2.0250942029414403\n",
      "Absolute Error_Difference= 0.00029651079841785943 Object Function: 2.0247976921430224\n",
      "Absolute Error_Difference= 0.0002945618335097322 Object Function: 2.0245031303095127\n",
      "Absolute Error_Difference= 0.00029262567911736426 Object Function: 2.0242105046303953\n",
      "Absolute Error_Difference= 0.00029070225107741265 Object Function: 2.023919802379318\n",
      "Absolute Error_Difference= 0.000288791465717253 Object Function: 2.0236310109136006\n",
      "Absolute Error_Difference= 0.000286893239962005 Object Function: 2.0233441176736386\n",
      "Absolute Error_Difference= 0.0002850074912368328 Object Function: 2.023059110182402\n",
      "Absolute Error_Difference= 0.00028313413750735705 Object Function: 2.0227759760448945\n",
      "Absolute Error_Difference= 0.00028127309737335793 Object Function: 2.022494702947521\n",
      "Absolute Error_Difference= 0.00027942428981875267 Object Function: 2.0222152786577023\n",
      "Absolute Error_Difference= 0.0002775876344998096 Object Function: 2.0219376910232025\n",
      "Absolute Error_Difference= 0.00027576305148535596 Object Function: 2.021661927971717\n",
      "Absolute Error_Difference= 0.0002739504614748256 Object Function: 2.0213879775102424\n",
      "Absolute Error_Difference= 0.0002721497855762145 Object Function: 2.021115827724666\n",
      "Absolute Error_Difference= 0.0002703609455636524 Object Function: 2.0208454667791025\n",
      "Absolute Error_Difference= 0.0002685838635785309 Object Function: 2.020576882915524\n",
      "Absolute Error_Difference= 0.00026681846234311024 Object Function: 2.020310064453181\n",
      "Absolute Error_Difference= 0.00026506466509168547 Object Function: 2.020044999788089\n",
      "Absolute Error_Difference= 0.0002633223955363917 Object Function: 2.0197816773925528\n",
      "Absolute Error_Difference= 0.0002615915779293765 Object Function: 2.0195200858146234\n",
      "Absolute Error_Difference= 0.0002598721369664325 Object Function: 2.019260213677657\n",
      "Absolute Error_Difference= 0.00025816399790823397 Object Function: 2.0190020496797487\n",
      "Absolute Error_Difference= 0.0002564670864262375 Object Function: 2.0187455825933225\n",
      "Absolute Error_Difference= 0.00025478132874878767 Object Function: 2.0184908012645737\n",
      "Absolute Error_Difference= 0.0002531066515536473 Object Function: 2.01823769461302\n",
      "Absolute Error_Difference= 0.00025144298200885373 Object Function: 2.017986251631011\n",
      "Absolute Error_Difference= 0.0002497902477505143 Object Function: 2.0177364613832607\n",
      "Absolute Error_Difference= 0.0002481483769214421 Object Function: 2.0174883130063392\n",
      "Absolute Error_Difference= 0.0002465172981040986 Object Function: 2.017241795708235\n",
      "Absolute Error_Difference= 0.0002448969403632262 Object Function: 2.016996898767872\n",
      "Absolute Error_Difference= 0.0002432872332338576 Object Function: 2.016753611534638\n",
      "Absolute Error_Difference= 0.0002416881067062171 Object Function: 2.016511923427932\n",
      "Absolute Error_Difference= 0.00024009949123993124 Object Function: 2.016271823936692\n",
      "Absolute Error_Difference= 0.00023852131772761354 Object Function: 2.0160333026189643\n",
      "Absolute Error_Difference= 0.00023695351754504657 Object Function: 2.0157963491014192\n",
      "Absolute Error_Difference= 0.0002353960225174312 Object Function: 2.015560953078902\n",
      "Absolute Error_Difference= 0.0002338487649087284 Object Function: 2.015327104313993\n",
      "Absolute Error_Difference= 0.0002323116774167744 Object Function: 2.0150947926365763\n",
      "Absolute Error_Difference= 0.00023078469318882355 Object Function: 2.0148640079433875\n",
      "Absolute Error_Difference= 0.000229267745843309 Object Function: 2.014634740197544\n",
      "Absolute Error_Difference= 0.0002277607693739192 Object Function: 2.0144069794281703\n",
      "Absolute Error_Difference= 0.00022626369825795578 Object Function: 2.0141807157299123\n",
      "Absolute Error_Difference= 0.00022477646738838786 Object Function: 2.013955939262524\n",
      "Absolute Error_Difference= 0.00022329901210360603 Object Function: 2.0137326402504203\n",
      "Absolute Error_Difference= 0.00022183126810082499 Object Function: 2.0135108089823195\n",
      "Absolute Error_Difference= 0.00022037317159684378 Object Function: 2.0132904358107226\n",
      "Absolute Error_Difference= 0.0002189246591486338 Object Function: 2.013071511151574\n",
      "Absolute Error_Difference= 0.00021748566777768374 Object Function: 2.0128540254837963\n",
      "Absolute Error_Difference= 0.00021605613488606679 Object Function: 2.0126379693489103\n",
      "Absolute Error_Difference= 0.00021463599831061941 Object Function: 2.0124233333505996\n",
      "Absolute Error_Difference= 0.00021322519630340153 Object Function: 2.0122101081542962\n",
      "Absolute Error_Difference= 0.00021182366748817572 Object Function: 2.011998284486808\n",
      "Absolute Error_Difference= 0.00021043135091947107 Object Function: 2.0117878531358886\n",
      "Absolute Error_Difference= 0.00020904818603373343 Object Function: 2.011578804949855\n",
      "Absolute Error_Difference= 0.0002076741127088333 Object Function: 2.011371130837146\n",
      "Absolute Error_Difference= 0.00020630907114682628 Object Function: 2.011164821765999\n",
      "Absolute Error_Difference= 0.00020495300201117672 Object Function: 2.010959868763988\n",
      "Absolute Error_Difference= 0.00020360584631129441 Object Function: 2.0107562629176767\n",
      "Absolute Error_Difference= 0.00020226754546071035 Object Function: 2.010553995372216\n",
      "Absolute Error_Difference= 0.00020093804127085946 Object Function: 2.010353057330945\n",
      "Absolute Error_Difference= 0.00019961727589468126 Object Function: 2.0101534400550505\n",
      "Absolute Error_Difference= 0.00019830519192343132 Object Function: 2.009955134863127\n",
      "Absolute Error_Difference= 0.0001970017322587836 Object Function: 2.0097581331308683\n",
      "Absolute Error_Difference= 0.0001957068402460571 Object Function: 2.009562426290622\n",
      "Absolute Error_Difference= 0.00019442045954631837 Object Function: 2.009368005831076\n",
      "Absolute Error_Difference= 0.00019314253422075822 Object Function: 2.009174863296855\n",
      "Absolute Error_Difference= 0.0001918730087222542 Object Function: 2.008982990288133\n",
      "Absolute Error_Difference= 0.00019061182778434826 Object Function: 2.0087923784603485\n",
      "Absolute Error_Difference= 0.00018935893660021463 Object Function: 2.0086030195237483\n",
      "Absolute Error_Difference= 0.00018811428066856095 Object Function: 2.0084149052430798\n",
      "Absolute Error_Difference= 0.0001868778058478071 Object Function: 2.008228027437232\n",
      "Absolute Error_Difference= 0.0001856494583871715 Object Function: 2.0080423779788448\n",
      "Absolute Error_Difference= 0.00018442918482897142 Object Function: 2.007857948794016\n",
      "Absolute Error_Difference= 0.0001832169321605015 Object Function: 2.0076747318618553\n",
      "Absolute Error_Difference= 0.00018201264759909463 Object Function: 2.007492719214256\n",
      "Absolute Error_Difference= 0.00018081627879951157 Object Function: 2.0073119029354567\n",
      "Absolute Error_Difference= 0.0001796277737518004 Object Function: 2.007132275161705\n",
      "Absolute Error_Difference= 0.0001784470807217886 Object Function: 2.006953828080983\n",
      "Absolute Error_Difference= 0.00017727414840296163 Object Function: 2.00677655393258\n",
      "Absolute Error_Difference= 0.0001761089257419357 Object Function: 2.006600445006838\n",
      "Absolute Error_Difference= 0.00017495136211032047 Object Function: 2.006425493644728\n",
      "Absolute Error_Difference= 0.00017380140713152414 Object Function: 2.0062516922375964\n",
      "Absolute Error_Difference= 0.0001726590108166448 Object Function: 2.0060790332267797\n",
      "Absolute Error_Difference= 0.0001715241234552245 Object Function: 2.0059075091033245\n",
      "Absolute Error_Difference= 0.00017039669571206062 Object Function: 2.0057371124076124\n",
      "Absolute Error_Difference= 0.00016927667854682582 Object Function: 2.0055678357290656\n",
      "Absolute Error_Difference= 0.000168164023258921 Object Function: 2.0053996717058067\n",
      "Absolute Error_Difference= 0.00016705868145105995 Object Function: 2.0052326130243556\n",
      "Absolute Error_Difference= 0.00016596060504214805 Object Function: 2.0050666524193135\n",
      "Absolute Error_Difference= 0.00016486974631213513 Object Function: 2.0049017826730013\n",
      "Absolute Error_Difference= 0.0001637860577665684 Object Function: 2.0047379966152348\n",
      "Absolute Error_Difference= 0.00016270949231822485 Object Function: 2.0045752871229165\n",
      "Absolute Error_Difference= 0.0001616400031250187 Object Function: 2.0044136471197915\n",
      "Absolute Error_Difference= 0.00016057754368326016 Object Function: 2.0042530695761083\n",
      "Absolute Error_Difference= 0.000159522067800566 Object Function: 2.0040935475083077\n",
      "Absolute Error_Difference= 0.0001584735295456774 Object Function: 2.003935073978762\n",
      "Absolute Error_Difference= 0.0001574318833199584 Object Function: 2.003777642095442\n",
      "Absolute Error_Difference= 0.00015639708385561946 Object Function: 2.0036212450115864\n",
      "Absolute Error_Difference= 0.00015536908612068245 Object Function: 2.0034658759254658\n",
      "Absolute Error_Difference= 0.00015434784539802848 Object Function: 2.0033115280800677\n",
      "Absolute Error_Difference= 0.00015333331730715827 Object Function: 2.0031581947627606\n",
      "Absolute Error_Difference= 0.00015232545769805483 Object Function: 2.0030058693050625\n",
      "Absolute Error_Difference= 0.0001513242227417777 Object Function: 2.0028545450823207\n",
      "Absolute Error_Difference= 0.00015032956891225524 Object Function: 2.0027042155134085\n",
      "Absolute Error_Difference= 0.00014934145294143164 Object Function: 2.002554874060467\n",
      "Absolute Error_Difference= 0.00014835983184591228 Object Function: 2.002406514228621\n",
      "Absolute Error_Difference= 0.00014738466294783592 Object Function: 2.0022591295656733\n",
      "Absolute Error_Difference= 0.00014641590383135394 Object Function: 2.002112713661842\n",
      "Absolute Error_Difference= 0.00014545351237993387 Object Function: 2.001967260149462\n",
      "Absolute Error_Difference= 0.00014449744671285458 Object Function: 2.001822762702749\n",
      "Absolute Error_Difference= 0.00014354766526736285 Object Function: 2.001679215037482\n",
      "Absolute Error_Difference= 0.00014260412671918132 Object Function: 2.0015366109107626\n",
      "Absolute Error_Difference= 0.00014166679006644145 Object Function: 2.001394944120696\n",
      "Absolute Error_Difference= 0.00014073561452265793 Object Function: 2.0012542085061735\n",
      "Absolute Error_Difference= 0.00013981055960066158 Object Function: 2.001114397946573\n",
      "Absolute Error_Difference= 0.00013889158503577193 Object Function: 2.000975506361537\n",
      "Absolute Error_Difference= 0.00013797865092346484 Object Function: 2.0008375277106136\n",
      "Absolute Error_Difference= 0.00013707171749732794 Object Function: 2.0007004559931163\n",
      "Absolute Error_Difference= 0.00013617074536176332 Object Function: 2.0005642852477545\n",
      "Absolute Error_Difference= 0.00013527569530902284 Object Function: 2.0004290095524455\n",
      "Absolute Error_Difference= 0.0001343865284075818 Object Function: 2.000294623024038\n",
      "Absolute Error_Difference= 0.00013350320601368537 Object Function: 2.0001611198180242\n",
      "Absolute Error_Difference= 0.00013262568968475108 Object Function: 2.0000284941283395\n",
      "Absolute Error_Difference= 0.00013175394129172346 Object Function: 1.9998967401870478\n",
      "Absolute Error_Difference= 0.00013088792286319872 Object Function: 1.9997658522641846\n",
      "Absolute Error_Difference= 0.00013002759679303644 Object Function: 1.9996358246673915\n",
      "Absolute Error_Difference= 0.00012917292565006733 Object Function: 1.9995066517417415\n",
      "Absolute Error_Difference= 0.00012832387224515074 Object Function: 1.9993783278694963\n",
      "Absolute Error_Difference= 0.0001274803996738072 Object Function: 1.9992508474698225\n",
      "Absolute Error_Difference= 0.00012664247124871686 Object Function: 1.9991242049985738\n",
      "Absolute Error_Difference= 0.00012581005052147987 Object Function: 1.9989983949480523\n",
      "Absolute Error_Difference= 0.00012498310130459878 Object Function: 1.9988734118467477\n",
      "Absolute Error_Difference= 0.0001241615875955393 Object Function: 1.9987492502591522\n",
      "Absolute Error_Difference= 0.000123345473719505 Object Function: 1.9986259047854327\n",
      "Absolute Error_Difference= 0.00012253472414780475 Object Function: 1.9985033700612849\n",
      "Absolute Error_Difference= 0.0001217293036390732 Object Function: 1.9983816407576458\n",
      "Absolute Error_Difference= 0.00012092917716111096 Object Function: 1.9982607115804847\n",
      "Absolute Error_Difference= 0.00012013430989665785 Object Function: 1.998140577270588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute Error_Difference= 0.00011934466730378901 Object Function: 1.9980212326032842\n",
      "Absolute Error_Difference= 0.00011856021503375835 Object Function: 1.9979026723882505\n",
      "Absolute Error_Difference= 0.00011778091895342513 Object Function: 1.997784891469297\n",
      "Absolute Error_Difference= 0.00011700674520565002 Object Function: 1.9976678847240914\n",
      "Absolute Error_Difference= 0.00011623766007851088 Object Function: 1.997551647064013\n",
      "Absolute Error_Difference= 0.0001154736301554049 Object Function: 1.9974361734338575\n",
      "Absolute Error_Difference= 0.00011471462220336015 Object Function: 1.9973214588116541\n",
      "Absolute Error_Difference= 0.00011396060320678636 Object Function: 1.9972074982084473\n",
      "Absolute Error_Difference= 0.00011321154037435832 Object Function: 1.997094286668073\n",
      "Absolute Error_Difference= 0.00011246740112613729 Object Function: 1.9969818192669468\n",
      "Absolute Error_Difference= 0.00011172815312265882 Object Function: 1.9968700911138242\n",
      "Absolute Error_Difference= 0.00011099376416479068 Object Function: 1.9967590973496594\n",
      "Absolute Error_Difference= 0.00011026420237425505 Object Function: 1.9966488331472851\n",
      "Absolute Error_Difference= 0.0001095394359671431 Object Function: 1.996539293711318\n",
      "Absolute Error_Difference= 0.00010881943347240686 Object Function: 1.9964304742778456\n",
      "Absolute Error_Difference= 0.00010810416353468355 Object Function: 1.996322370114311\n",
      "Absolute Error_Difference= 0.0001073935950637317 Object Function: 1.9962149765192472\n",
      "Absolute Error_Difference= 0.00010668769716937199 Object Function: 1.9961082888220778\n",
      "Absolute Error_Difference= 0.00010598643913262151 Object Function: 1.9960023023829452\n",
      "Absolute Error_Difference= 0.0001052897904652017 Object Function: 1.99589701259248\n",
      "Absolute Error_Difference= 0.00010459772087534347 Object Function: 1.9957924148716046\n",
      "Absolute Error_Difference= 0.00010391020025157793 Object Function: 1.995688504671353\n",
      "Absolute Error_Difference= 0.00010322719869271246 Object Function: 1.9955852774726603\n",
      "Absolute Error_Difference= 0.0001025486865124936 Object Function: 1.9954827287861479\n",
      "Absolute Error_Difference= 0.00010187463418653842 Object Function: 1.9953808541519613\n",
      "Absolute Error_Difference= 0.00010120501240806767 Object Function: 1.9952796491395532\n",
      "Absolute Error_Difference= 0.00010053979205326691 Object Function: 1.9951791093475\n",
      "Absolute Error_Difference= 9.98789441812864e-05 Object Function: 1.9950792304033187\n",
      "-0.013646209730739252\n",
      "30.197282181568365\n",
      "1113\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Question 3 Answer Code\n",
    "# Write code for you answer to this question in this box\n",
    "# Do not delete these comments, otherwise you will get zero for this answer.\n",
    "# Make sure your code has run and the answer is correct *before* submitting your notebook for marking.\n",
    "\n",
    "m= -0.4\n",
    "c = 80\n",
    "x_testvals = np.linspace(1888, 2020, 27)[:, None]\n",
    "# print(x_testvals)\n",
    "error_old = 0\n",
    "it=0 #iteration\n",
    "while(True):\n",
    "    for i in np.arange(10):\n",
    "        m = ((y - c)*x).sum()/(x*x).sum()\n",
    "        c = (y-m*x).sum()/y.shape[0] \n",
    "    obj_fun = 0\n",
    "    error_diff = 0     \n",
    "    obj_fun = np.square(y - m*x- c).sum()\n",
    "    error_new = obj_fun\n",
    "    error_diff = abs(error_new-error_old)\n",
    "    error_old = error_new \n",
    "    it=it+1\n",
    "    print(\"Absolute Error_Difference=\", error_diff,\"Object Function:\",obj_fun)\n",
    "    if(error_diff < 0.0001):  \n",
    "        break\n",
    "f_testvals = m*x_testvals + c           \n",
    "plt.plot(x_testvals, f_testvals, 'g-')\n",
    "plt.plot(x, y, 'rx')\n",
    "print(m)\n",
    "print(c)\n",
    "print(it)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3 Answer Here\n",
    "\n",
    "Write your answer to the question in this box.\n",
    "\n",
    "In the above code, we are updating only one parameter in every iteration. Therefore,we need more number of iteration to plot a good graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Input Solution with Linear Algebra\n",
    "\n",
    "You've now seen how slow it can be to perform a coordinate ascent on a system. Another approach to solving the system (which is not always possible, particularly in *non-linear* systems) is to go direct to the minimum. To do this we need to introduce *linear algebra*. We will represent all our errors and functions in the form of linear algebra. \n",
    "\n",
    "As we mentioned above, linear algebra is just a shorthand for performing lots of multiplications and additions simultaneously. What does it have to do with our system then? Well the first thing to note is that the linear function we were trying to fit has the following form:\n",
    "$$\n",
    "f(x) = mx + c\n",
    "$$\n",
    "the classical form for a straight line. From a linear algebraic perspective we are looking for multiplications and additions. We are also looking to separate our parameters from our data. The data is the *givens* remember, in French the word is données literally translated means *givens* that's great, because we don't need to change the data, what we need to change are the parameters (or variables) of the model. In this function the data comes in through $x$, and the parameters are $m$ and $c$. \n",
    "\n",
    "What we'd like to create is a vector of parameters and a vector of data. Then we could represent the system with vectors that represent the data, and vectors that represent the parameters. \n",
    "\n",
    "We look to turn the multiplications and additions into a linear algebraic form, we have one multiplication ($m\\times c$) and one addition ($mx + c$). But we can turn this into a inner product by writing it in the following way,\n",
    "$$\n",
    "f(x) = m \\times x + c \\times 1,\n",
    "$$\n",
    "in other words we've extracted the unit value, from the offset, $c$. We can think of this unit value like an extra item of data, because it is always given to us, and it is always set to 1 (unlike regular data, which is likely to vary!). We can therefore write each input data location, $\\mathbf{x}$, as a vector\n",
    "$$\n",
    "\\mathbf{x} = \\begin{bmatrix} 1\\\\ x\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Now we choose to also turn our parameters into a vector. The parameter vector will be defined to contain \n",
    "$$\n",
    "\\mathbf{w} = \\begin{bmatrix} c \\\\ m\\end{bmatrix}\n",
    "$$\n",
    "because if we now take the inner product between these to vectors we recover\n",
    "$$\n",
    "\\mathbf{x}\\cdot\\mathbf{w} = 1 \\times c + x \\times m = mx + c\n",
    "$$\n",
    "In `numpy` we can define this vector as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the vector w\n",
    "w = np.zeros(shape=(2, 1))\n",
    "w[0] = m\n",
    "w[1] = c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us the equivalence between original operation and an operation in vector space. Whilst the notation here isn't a lot shorter, the beauty is that we will be able to add as many features as we like and still keep the same representation. In general, we are now moving to a system where each of our predictions is given by an inner product. When we want to represent a linear product in linear algebra, we tend to do it with the transpose operation, so since we have $\\mathbf{a}\\cdot\\mathbf{b} = \\mathbf{a}^\\top\\mathbf{b}$ we can write\n",
    "$$\n",
    "f(\\mathbf{x}_i) = \\mathbf{x}_i^\\top\\mathbf{w}.\n",
    "$$\n",
    "Where we've assumed that each data point, $\\mathbf{x}_i$, is now written by appending a 1 onto the original vector\n",
    "$$\n",
    "\\mathbf{x}_i = \n",
    "\\begin{bmatrix} \n",
    "1 \\\\\n",
    "x_i\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "## Design Matrix\n",
    "\n",
    "We can do this for the entire data set to form a [*design matrix*](http://en.wikipedia.org/wiki/Design_matrix) $\\mathbf{X}$,\n",
    "\n",
    "$$\\mathbf{X} = \\begin{bmatrix} \n",
    "\\mathbf{x}_1^\\top \\\\\\ \n",
    "\\mathbf{x}_2^\\top \\\\\\ \n",
    "\\vdots \\\\\\\n",
    "\\mathbf{x}_n^\\top\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "1 & x_1 \\\\\\\n",
    "1 & x_2 \\\\\\\n",
    "\\vdots & \\vdots \\\\\\\n",
    "1 & x_n \n",
    "\\end{bmatrix},$$\n",
    "\n",
    "which in `numpy` can be done with the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((np.ones_like(x), x))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the Objective with Linear Algebra\n",
    "\n",
    "When we think of the objective function, we can think of it as the errors where the error is defined in a similar way to what it was in Legendre's day $y_i - f(\\mathbf{x}_i)$, in statistics these errors are also sometimes called [*residuals*](http://en.wikipedia.org/wiki/Errors_and_residuals_in_statistics). So we can think as the objective and the prediction function as two separate parts, first we have,\n",
    "$$\n",
    "E(\\mathbf{w}) = \\sum_{i=1}^n (y_i - f(\\mathbf{x}_i; \\mathbf{w}))^2,\n",
    "$$\n",
    "where we've made the function $f(\\cdot)$'s dependence on the parameters $\\mathbf{w}$ explicit in this equation. Then we have the definition of the function itself,\n",
    "$$\n",
    "f(\\mathbf{x}_i; \\mathbf{w}) = \\mathbf{x}_i^\\top \\mathbf{w}.\n",
    "$$\n",
    "Let's look again at these two equations and see if we can identify any inner products. The first equation is a sum of squares, which is promising. Any sum of squares can be represented by an inner product,\n",
    "$$\n",
    "a = \\sum_{i=1}^{k} b^2_i = \\mathbf{b}^\\top\\mathbf{b},\n",
    "$$\n",
    "so if we wish to represent $E(\\mathbf{w})$ in this way, all we need to do is convert the sum operator to an inner product. We can get a vector from that sum operator by placing both $y_i$ and $f(\\mathbf{x}_i; \\mathbf{w})$ into vectors, which we do by defining \n",
    "$$\n",
    "\\mathbf{y} = \\begin{bmatrix}y_1\\\\y_2\\\\ \\vdots \\\\ y_n\\end{bmatrix}\n",
    "$$\n",
    "and defining\n",
    "$$\n",
    "\\mathbf{f}(\\mathbf{X}; \\mathbf{w}) = \\begin{bmatrix}f(\\mathbf{x}_1; \\mathbf{w})\\\\f(\\mathbf{x}_2; \\mathbf{w})\\\\ \\vdots \\\\ f(\\mathbf{x}_n; \\mathbf{w})\\end{bmatrix}.\n",
    "$$\n",
    "The second of these is actually a vector-valued function. This term may appear intimidating, but the idea is straightforward. A vector valued function is simply a vector whose elements are themselves defined as *functions*, i.e. it is a vector of functions, rather than a vector of scalars. The idea is so straightforward, that we are going to ignore it for the moment, and barely use it in the derivation. But it will reappear later when we introduce *basis functions*. So we will, for the moment, ignore the dependence of $\\mathbf{f}$ on $\\mathbf{w}$ and $\\mathbf{X}$ and simply summarise it by a vector of numbers\n",
    "$$\n",
    "\\mathbf{f} = \\begin{bmatrix}f_1\\\\f_2\\\\ \\vdots \\\\ f_n\\end{bmatrix}.\n",
    "$$\n",
    "This allows us to write our objective in the folowing, linear algebraic form,\n",
    "$$\n",
    "E(\\mathbf{w}) = (\\mathbf{y} - \\mathbf{f})^\\top(\\mathbf{y} - \\mathbf{f})\n",
    "$$\n",
    "from the rules of inner products.\n",
    "\n",
    "But what of our matrix $\\mathbf{X}$ of input data? At this point, we need to dust off [*matrix-vector multiplication*](http://en.wikipedia.org/wiki/Matrix_multiplication). Matrix multiplication is simply a convenient way of performing many inner products together, and it's exactly what we need to summarise the operation\n",
    "$$\n",
    "f_i = \\mathbf{x}_i^\\top\\mathbf{w}.\n",
    "$$\n",
    "This operation tells us that each element of the vector $\\mathbf{f}$ (our vector valued function) is given by an inner product between $\\mathbf{x}_i$ and $\\mathbf{w}$. In other words it is a series of inner products. Let's look at the definition of matrix multiplication, it takes the form\n",
    "$$\n",
    "\\mathbf{c} = \\mathbf{B}\\mathbf{a}\n",
    "$$\n",
    "where $\\mathbf{c}$ might be a $k$ dimensional vector (which we can intepret as a $k\\times 1$ dimensional matrix), and $\\mathbf{B}$ is a $k\\times k$ dimensional matrix and $\\mathbf{a}$ is a $k$ dimensional vector ($k\\times 1$ dimensional matrix). \n",
    "\n",
    "The result of this multiplication is of the form\n",
    "$$\n",
    "\\begin{bmatrix}c_1\\\\c_2 \\\\ \\vdots \\\\ a_k\\end{bmatrix} = \n",
    "\\begin{bmatrix} b_{1,1} & b_{1, 2} & \\dots & b_{1, k} \\\\\n",
    "b_{2, 1} & b_{2, 2} & \\dots & b_{2, k} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "b_{k, 1} & b_{k, 2} & \\dots & b_{k, k} \\end{bmatrix} \\begin{bmatrix}a_1\\\\a_2 \\\\ \\vdots\\\\ c_k\\end{bmatrix} = \\begin{bmatrix} b_{1, 1}a_1 + b_{1, 2}a_2 + \\dots + b_{1, k}a_k\\\\\n",
    "b_{2, 1}a_1 + b_{2, 2}a_2 + \\dots + b_{2, k}a_k \\\\ \n",
    "\\vdots\\\\ \n",
    "b_{k, 1}a_1 + b_{k, 2}a_2 + \\dots + b_{k, k}a_k\\end{bmatrix}\n",
    "$$\n",
    "so we see that each element of the result, $\\mathbf{a}$ is simply the inner product between each *row* of $\\mathbf{B}$ and the vector $\\mathbf{c}$. Because we have defined each element of $\\mathbf{f}$ to be given by the inner product between each *row* of the design matrix and the vector $\\mathbf{w}$ we now can write the full operation in one matrix multiplication,\n",
    "$$\n",
    "\\mathbf{f} = \\mathbf{X}\\mathbf{w}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.dot(X, w) # np.dot does matrix multiplication in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining this result with our objective function,\n",
    "$$\n",
    "E(\\mathbf{w}) = (\\mathbf{y} - \\mathbf{f})^\\top(\\mathbf{y} - \\mathbf{f})\n",
    "$$\n",
    "we find we have defined the *model* with two equations. One equation tells us the form of our predictive function and how it depends on its parameters, the other tells us the form of our objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resid = (y-f)\n",
    "E = np.dot(resid.T, resid) # matrix multiplication on a single vector is equivalent to a dot product.\n",
    "print(\"Error function is:\", E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Question 4\n",
    "\n",
    "The prediction for our movie recommender system had the form\n",
    "$$\n",
    "f_{i,j} = \\mathbf{u}_i^\\top \\mathbf{v}_j\n",
    "$$\n",
    "and the objective function was then\n",
    "$$\n",
    "E = \\sum_{i,j} s_{i,j}(y_{i,j} - f_{i, j})^2\n",
    "$$\n",
    "Try writing this down in matrix and vector form. How many of the terms can you do? For each variable and parameter carefully think about whether it should be represented as a matrix or vector. Do as many of the terms as you can. Use $\\LaTeX$ to give your answers and give the *dimensions* of any matrices you create.\n",
    "\n",
    "*20 marks* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4 Answer\n",
    "\n",
    "Write your answer to the question in this box.\n",
    "\n",
    "In the below given matrix, $v_{j,1}$ represent the east west direction and $v_{j,2}$ represents north south direction. $i$th term is used here to represent the user location.\n",
    "\n",
    "$$\n",
    "\\mathbf{v}j = \\begin{bmatrix} v_{j,1} \\\\ v_{j,2}\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{u}i = \\begin{bmatrix} u_{i,1} \\\\ u_{i,2}\\end{bmatrix}.\n",
    "$$\n",
    "$y_{i,j}$ here represents $i$'s affinity for $j$th item. \n",
    "$$\n",
    "\\mathbf{u}_i^\\top= \\begin{bmatrix}\n",
    "u_{i,1} \\ u_{i,2}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "<B>Prediction function:</B> \n",
    "$$\n",
    "f_{i,j} =  \\begin{bmatrix}\n",
    "u_{i,1} \\ u_{i,2}\n",
    "\\end{bmatrix}\\begin{bmatrix} v_{j,1} \\\\ v_{j,2}\\end{bmatrix} = \\begin{bmatrix} u_{i,1}v_{j,1} + u_{i,2}v_{j,2} \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Making matrix of Y\n",
    "\n",
    "$$\n",
    "\\mathbf{Y} = \\begin{bmatrix} y_{1,1} & \\dots & y_{1, m} \\\\\n",
    "y_{2, 1} & \\dots & y_{2, m} \\\\\n",
    "\\vdots & \\ddots  & \\vdots \\\\\n",
    "y_{n, 1} & \\dots & y_{n, m} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf{S} = \\begin{bmatrix} s_{1,1} & \\dots & s_{1, m} \\\\\n",
    "s_{2, 1} &\\dots & s_{2, m} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "s_{n, 1} & \\dots & s_{n, m} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "F=\\begin{bmatrix} u_{1, 1}v_{1, 1} + u_{1, 2}v_{1, 2} & +\\dots + &  u_{1, 1}v_{m, 1} + u_{1, 2}v_{m, 2}\\\\\n",
    "u_{2, 1}v_{1, 1} + u_{2, 2}v_{1, 2} & +\\dots + &  u_{2, 1}v_{m, 1} + u_{2, 2}v_{m, 2}\\\\\n",
    "\\vdots\\\\\n",
    "u_{n, 1}v_{1, 1} + u_{n, n}v_{1, 2} & +\\dots + & u_{n, 1}v_{m, 1} + u_{n, 2}v_{m, 2}\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "Y-F=\\begin{bmatrix} y_{1,1}-(u_{1, 1}v_{1, 1} + u_{1, 2}v_{1, 2}) & +\\dots + &  y_{1, m}-(u_{1, 1}v_{m, 1} + u_{1, 2}v_{m, 2})\\\\\n",
    "y_{2, 1}-(u_{2, 1}v_{1, 1} + u_{2, 2}v_{1, 2}) & +\\dots + &  y_{2, m}-(u_{2, 1}v_{m, 1} + u_{2, 2}v_{m, 2})\\\\\n",
    "\\vdots\\\\\n",
    "y_{n, 1}-(u_{n, 1}v_{1, 1} + u_{n, n}v_{1, 2}) & +\\dots + & y_{n, m}-(u_{n, 1}v_{m, 1} + u_{n, 2}v_{m, 2})\\end{bmatrix} \\dots \\textrm{equation(1)}\n",
    "$$ \n",
    "\n",
    "$$\n",
    "{(Y-F)}^T=\\begin{bmatrix} y_{1,1}-(u_{1, 1}v_{1, 1} + u_{1, 2}v_{1, 2}) & +\\dots + &  y_{n, 1}-(u_{n, 1}v_{1, 1} + u_{n, n}v_{1, 2})\\\\\n",
    "y_{1, 2}-(u_{1, 1}v_{2, 1} + u_{1, 2}v_{2, 2}) & +\\dots + &  y_{n, 2}-(u_{n, 1}v_{2, 1} + u_{n, n}v_{m, m})\\\\\n",
    "\\vdots\\\\\n",
    "y_{1, m}-(u_{1, 1}v_{m, 1} + u_{1, 2}v_{m, 2}) &  +\\dots + & y_{n, m}-(u_{n, 1}v_{m, 1} + u_{n, 2}v_{m, 2})\\end{bmatrix} \\dots \\textrm{equation(2)}\n",
    "$$\n",
    "\n",
    "Subsituting value of equation 1 and 2 in below given equation\n",
    "\n",
    "\n",
    "$$\n",
    "E(\\mathbf{w}) = (\\mathbf{y} - \\mathbf{f})^\\top(\\mathbf{y} - \\mathbf{f}) = \\begin{bmatrix} y_{1,1}-(u_{1, 1}v_{1, 1} + u_{1, 2}v_{1, 2}) & +\\dots + &  y_{n, 1}-(u_{n, 1}v_{1, 1} + u_{n, n}v_{1, 2})\\\\\n",
    "y_{1, 2}-(u_{1, 1}v_{2, 1} + u_{1, 2}v_{2, 2}) & +\\dots + &  y_{n, 2}-(u_{n, 1}v_{2, 1} + u_{n, n}v_{m, m})\\\\\n",
    "\\vdots\\\\\n",
    "y_{1, m}-(u_{1, 1}v_{m, 1} + u_{1, 2}v_{m, 2}) &  +\\dots + & y_{n, m}-(u_{n, 1}v_{m, 1} + u_{n, 2}v_{m, 2})\\end{bmatrix}\\begin{bmatrix} y_{1,1}-(u_{1, 1}v_{1, 1} + u_{1, 2}v_{1, 2}) & +\\dots + &  y_{1, m}-(u_{1, 1}v_{m, 1} + u_{1, 2}v_{m, 2})\\\\\n",
    "y_{2, 1}-(u_{2, 1}v_{1, 1} + u_{2, 2}v_{1, 2}) & +\\dots + &  y_{2, m}-(u_{2, 1}v_{m, 1} + u_{2, 2}v_{m, 2})\\\\\n",
    "\\vdots\\\\\n",
    "y_{n, 1}-(u_{n, 1}v_{1, 1} + u_{n, n}v_{1, 2}) &  +\\dots + & y_{n, m}-(u_{n, 1}v_{m, 1} + u_{n, 2}v_{m, 2})\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "Final matrix needs lot of calculation and after calculation it will become more complex.Therefore, let take it as matrix $Q$ with dimension $mxm$. Let’s now multiple matrix $S$ with $Q$. \n",
    "\n",
    "$$\\mathbf{Q} = \\begin{bmatrix} q_{1,1} & \\dots & q_{1,m} \\\\\n",
    "q_{2, 1} & \\dots & q_{2, m} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "q_{m, 1} & \\dots & q_{m, m} \\end{bmatrix}$$\n",
    "$$\\mathbf{} = \n",
    "\\begin{bmatrix} s_{1,1} & \\dots & s_{1,m} \\\\\n",
    "s_{2, 1} & \\dots & s_{2, m} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "s_{n, 1} & \\dots & s_{n, m} \\end{bmatrix}\n",
    "\\begin{bmatrix} q_{1,1} & \\dots & q_{1,m} \\\\\n",
    "q_{2, 1} & \\dots & q_{2, m} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "q_{m, 1}& \\dots & q_{m, m} \\end{bmatrix}$$\n",
    "\n",
    "Now $S$ has dimension $nxm$ and $Q$ has dimension $mxm$. After further calculating, we got result matrix C with dimension $nxm$.\n",
    "now taking sum of every element in $C$, having dimension $nxm$\n",
    "\n",
    "$$ \n",
    "E = \\sum C = \\sum_{ij}\\begin{bmatrix} \n",
    "s_{1,1}q_{1,1}+\\dots+s_{1,m}q_{m,1} & \\dots & s_{1,1}q_{m,1}+\\dots+s_{1,m}q_{m,m} \n",
    "\\\\\n",
    "s_{2,1}q_{1,1}+\\dots+s_{2,m}q_{m,2} & \\dots & s_{2,1}q_{m,1}+\\dots+s_{2,m}q_{m,m}\n",
    "\\\\\n",
    "\\vdots & \\ddots & \\vdots \n",
    "\\\\\n",
    "s_{n,1}q_{1,1}+\\dots+s_{n,m}q_{m,1} & \\dots & s_{n,1}q_{1,m}+\\dots+s_{n,m}q_{m,m}\n",
    "\\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective Optimisation\n",
    "\n",
    "Our *model* has now been defined with two equations, the prediction function and the objective function. Next we will use multivariate calculus to define an *algorithm* to fit the model. The separation between model and algorithm is important and is often overlooked. Our model contains a function that shows how it will be used for prediction, and a function that describes the objective function we need to optimise to obtain a good set of parameters. \n",
    "\n",
    "The linear regression model we have described is still the same as the one we fitted above with a coordinate ascent algorithm. We have only played with the notation to obtain the same model in a matrix and vector notation. However, we will now fit this model with a different algorithm, one that is much faster. It is such a widely used algorithm that from the end user's perspective it doesn't even look like an algorithm, it just appears to be a single operation (or function). However, underneath the computer calls an algorithm to find the solution. Further, the algorithm we obtain is very widely used, and because of this it turns out to be highly optimised.\n",
    "\n",
    "Once again we are going to try and find the stationary points of our objective by finding the *stationary points*. However, the stationary points of a multivariate function, are a little bit more complext to find. Once again we need to find the point at which the derivative is zero, but now we need to use  *multivariate calculus* to find it. This involves learning a few additional rules of differentiation (that allow you to do the derivatives of a function with respect to  vector), but in the end it makes things quite a bit easier. We define vectorial derivatives as follows,\n",
    "$$\n",
    "\\frac{\\text{d}E(\\mathbf{w})}{\\text{d}\\mathbf{w}} = \\begin{bmatrix}\\frac{\\partial E(\\mathbf{w})}{\\partial w_1}\\\\\\frac{\\partial E(\\mathbf{w})}{\\partial w_2}\\end{bmatrix}.\n",
    "$$\n",
    "where $\\frac{\\partial E(\\mathbf{w})}{\\partial w_1}$ is the [partial derivative](http://en.wikipedia.org/wiki/Partial_derivative) of the error function with respect to $w_1$.\n",
    "\n",
    "Differentiation through multiplications and additions is relatively straightforward, and since linear algebra is just multiplication and addition, then its rules of diffentiation are quite straightforward too, but slightly more complex than regular derivatives. \n",
    "\n",
    "### Matrix Differentiation\n",
    "\n",
    "We will need two rules of differentiation. The first is diffentiation of an inner product. By remebering that the inner product is made up of multiplication and addition, we can hope that its derivative is quite straightforward, and so it proves to be. We can start by thinking about the definition of the inner product,\n",
    "$$\n",
    "\\mathbf{a}^\\top\\mathbf{z} = \\sum_{i} a_i z_i,\n",
    "$$\n",
    "which if we were to take the derivative with respect to $z_k$ would simply return the gradient of the one term in the sum for which the derivative was non zero, that of $a_k$, so we know that \n",
    "$$\n",
    "\\frac{\\text{d}}{\\text{d}z_k} \\mathbf{a}^\\top \\mathbf{z} = a_k\n",
    "$$\n",
    "and by our definition of multivariate derivatives we can simply stack all the partial derivatives of this form in a vector to obtain the result that\n",
    "$$\n",
    "\\frac{\\text{d}}{\\text{d}\\mathbf{z}} \\mathbf{a}^\\top \\mathbf{z} = \\mathbf{a}.\n",
    "$$\n",
    "The second rule that's required is differentiation of a 'matrix quadratic'. A scalar quadratic in $z$ with coefficient $c$ has the form $cz^2$. If $\\mathbf{z}$ is a $k\\times 1$ vector and $\\mathbf{C}$ is a $k \\times k$ *matrix* of coefficients then the matrix quadratic form is written as $\\mathbf{z}^\\top \\mathbf{C}\\mathbf{z}$, which is itself a *scalar* quantity, but it is a function of a *vector*. \n",
    "\n",
    "#### Matching Dimensions in Matrix Multiplications\n",
    "\n",
    "There's a trick for telling that it's a scalar result. When you are doing maths with matrices, it's always worth pausing to perform a quick sanity check on the dimensions. Matrix multplication only works when the dimensions match. To be precise, the 'inner' dimension of the matrix must match. What is the inner dimension. If we multiply two matrices $\\mathbf{A}$ and $\\mathbf{B}$, the first of which has $k$ rows and $\\ell$ columns and the second of which has $p$ rows and $q$ columns, then we can check whether the multiplication works by writing the dimensionalities next to each other,\n",
    "$$\n",
    "\\mathbf{A} \\mathbf{B} \\rightarrow (k \\times \\underbrace{\\ell)(p}_\\text{inner dimensions} \\times q) \\rightarrow (k\\times q).\n",
    "$$\n",
    "The inner dimensions are the two inside dimensions, $\\ell$ and $p$. The multiplication will only work if $\\ell=p$. The result of the multiplication will then be a $k\\times q$ matrix: this dimensionality comes from the 'outer dimensions'. Note that matrix multiplication is not [*commutative*](http://en.wikipedia.org/wiki/Commutative_property). And if you change the order of the multiplication, \n",
    "$$\n",
    "\\mathbf{B} \\mathbf{A} \\rightarrow (\\ell \\times \\underbrace{k)(q}_\\text{inner dimensions} \\times p) \\rightarrow (\\ell \\times p).\n",
    "$$\n",
    "firstly it may no longer even work, because now the condition is that $k=q$, and secondly the result could be of a different dimensionality. An exception is if the matrices are square matrices (e.g. same number of rows as columns) and they are both *symmetric*. A symmetric matrix is one for which $\\mathbf{A}=\\mathbf{A}^\\top$, or equivalently, $a_{i,j} = a_{j,i}$ for all $i$ and $j$.  \n",
    "\n",
    "You will need to get used to working with matrices and vectors applying and developing new machine learning techniques. You should have come across them before, but you may not have used them as extensively as we will now do in this course. You should get used to using this trick to check your work and ensure you know what the dimension of an output matrix should be. For our matrix quadratic form, it turns out that we can see it as a special type of inner product.\n",
    "$$\n",
    "\\mathbf{z}^\\top\\mathbf{C}\\mathbf{z} \\rightarrow (1\\times \\underbrace{k) (k}_\\text{inner dimensions}\\times k) (k\\times 1) \\rightarrow \\mathbf{b}^\\top\\mathbf{z}\n",
    "$$\n",
    "where $\\mathbf{b} = \\mathbf{C}\\mathbf{z}$ so therefore the result is a scalar,\n",
    "$$\n",
    "\\mathbf{b}^\\top\\mathbf{z} \\rightarrow (1\\times \\underbrace{k) (k}_\\text{inner dimensions}\\times 1) \\rightarrow (1\\times 1)\n",
    "$$\n",
    "where a $(1\\times 1)$ matrix is recognised as a scalar.\n",
    "\n",
    "This implies that we should be able to differentiate this form, and indeed the rule for its differentiation is slightly more complex than the inner product, but still quite simple,\n",
    "$$\n",
    "\\frac{\\text{d}}{\\text{d}\\mathbf{z}} \\mathbf{z}^\\top\\mathbf{C}\\mathbf{z}= \\mathbf{C}\\mathbf{z} + \\mathbf{C}^\\top \\mathbf{z}.\n",
    "$$\n",
    "Note that in the special case where $\\mathbf{C}$ is symmetric then we have $\\mathbf{C} = \\mathbf{C}^\\top$ and the derivative simplifies to \n",
    "$$\n",
    "\\frac{\\text{d}}{\\text{d}\\mathbf{z}} \\mathbf{z}^\\top\\mathbf{C}\\mathbf{z}= 2\\mathbf{C}\\mathbf{z}.\n",
    "$$\n",
    "### Differentiating the Objective\n",
    "\n",
    "First, we need to compute the full objective by substituting our prediction function into the objective function to obtain the objective in terms of $\\mathbf{w}$. Doing this we obtain\n",
    "$$\n",
    "E(\\mathbf{w})= (\\mathbf{y} - \\mathbf{X}\\mathbf{w})^\\top (\\mathbf{y} - \\mathbf{X}\\mathbf{w}).\n",
    "$$\n",
    "We now need to differentiate this *quadratic form* to find the minimum. We differentiate with respect to the *vector* $\\mathbf{w}$. But before we do that, we'll expand the brackets in the quadratic form to obtain a series of scalar terms. The rules for bracket expansion across the vectors are similar to those for the scalar system giving,\n",
    "$$\n",
    "(\\mathbf{a} - \\mathbf{b})^\\top (\\mathbf{c} - \\mathbf{d}) = \\mathbf{a}^\\top \\mathbf{c} - \\mathbf{a}^\\top \\mathbf{d} - \\mathbf{b}^\\top \\mathbf{c} + \\mathbf{b}^\\top \\mathbf{d}\n",
    "$$\n",
    "which substituting for $\\mathbf{a} = \\mathbf{c} = \\mathbf{y}$ and $\\mathbf{b}=\\mathbf{d} = \\mathbf{X}\\mathbf{w}$ gives\n",
    "$$\n",
    "E(\\mathbf{w})= \\mathbf{y}^\\top\\mathbf{y} - 2\\mathbf{y}^\\top\\mathbf{X}\\mathbf{w} + \\mathbf{w}^\\top\\mathbf{X}^\\top\\mathbf{X}\\mathbf{w}\n",
    "$$\n",
    "where we used the fact that $\\mathbf{y}^\\top\\mathbf{X}\\mathbf{w}= \\mathbf{w}^\\top\\mathbf{X}^\\top\\mathbf{y}$. Now we can use our rules of differentiation to compute the derivative of this form, which is,\n",
    "$$\n",
    "\\frac{\\text{d}}{\\text{d}\\mathbf{w}}E(\\mathbf{w})=- 2\\mathbf{X}^\\top \\mathbf{y} + 2\\mathbf{X}^\\top\\mathbf{X}\\mathbf{w},\n",
    "$$\n",
    "where we have exploited the fact that $\\mathbf{X}^\\top\\mathbf{X}$ is symmetric to obtain this result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Question 5\n",
    "\n",
    "Use the equivalence between our vector and our matrix formulations of linear regression, alongside our definition of vector derivates, to match the gradients we've computed directly for $\\frac{\\text{d}E(c, m)}{\\text{d}c}$ and $\\frac{\\text{d}E(c, m)}{\\text{d}m}$ to those for $\\frac{\\text{d}E(\\mathbf{w})}{\\text{d}\\mathbf{w}}$.\n",
    "\n",
    "*20 marks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5 Answer\n",
    "\n",
    "Write your answer to the question in this box.\n",
    "\n",
    "Considerining above equation(2) derived after differentiating equation(1).\n",
    "\n",
    "$$\n",
    "E(\\mathbf{w})= \\mathbf{y}^\\top\\mathbf{y} - 2\\mathbf{y}^\\top\\mathbf{X}\\mathbf{w} + \\mathbf{w}^\\top\\mathbf{X}^\\top\\mathbf{X}\\mathbf{w} \\dots \\textrm{equation(1)}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\text{d}E(\\mathbf{w})}{\\text{d}w} = - 2\\mathbf{X}^\\top \\mathbf{y} + 2\\mathbf{X}^\\top\\mathbf{X}\\mathbf{w} \\dots \\textrm{equation(2)}\n",
    "$$\n",
    "$$\n",
    "\\textrm{or}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\text{d}E(\\mathbf{w})}{\\text{d}w} =-  2(\\mathbf{X}^\\top \\mathbf{y} - \\mathbf{X}^\\top\\mathbf{X}\\mathbf{w})\n",
    "$$\n",
    "Now,analysing the variable in the above equation.\n",
    "\n",
    "$$\n",
    "\\mathbf{X}^\\top = \\begin{bmatrix}\n",
    "1 & \\dots & 1\\\\\\\n",
    "x_1 & \\dots & x_n \\\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{y} = \\begin{bmatrix} \n",
    "\\mathbf{y}_1 \\\\\\ \n",
    "\\vdots \\\\\\\n",
    "\\mathbf{y}_n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \\begin{bmatrix}\n",
    "1 & x_1 \\\\\\\n",
    "\\vdots & \\vdots \\\\\\\n",
    "1 & x_n \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{w} = \\begin{bmatrix} c \\\\ m\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Subsituting the above value in below given equation, which is part of equation(2).\n",
    "\n",
    "$$(\\mathbf{X}^\\top \\mathbf{y} - \\mathbf{X}^\\top\\mathbf{X}\\mathbf{w}) \\dots \\textrm{equation(3)}$$\n",
    "\n",
    "$$\n",
    "\\mathbf{X}^\\top \\mathbf{y} - \\mathbf{X}^\\top\\mathbf{X}\\mathbf{w} =  \\begin{bmatrix}\n",
    "1  & \\dots & 1\\\\\\\n",
    "x_1 & \\dots & x_n \\\\\\\n",
    "\\end{bmatrix}\\begin{bmatrix} \n",
    "\\mathbf{y}_1 \\\\\\ \n",
    "\\vdots \\\\\\\n",
    "\\mathbf{y}_n\n",
    "\\end{bmatrix} - \\begin{bmatrix}\n",
    "1 &  \\dots & 1\\\\\\\n",
    "x_1  & \\dots & x_n \\\\\\\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "1 & x_1 \\\\\\\n",
    "\\vdots & \\vdots \\\\\\\n",
    "1 & x_n \n",
    "\\end{bmatrix}\\begin{bmatrix} c \\\\ m\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{X}^\\top \\mathbf{y} - \\mathbf{X}^\\top\\mathbf{X}\\mathbf{w} = \n",
    "\\begin{bmatrix}y_1+y_2+ & \\dots \\ +y_n\\\\\n",
    "x_1y_1+x_2y_2+ & \\dots +x_ny_n\\\\\\\n",
    "\\end{bmatrix} - \\begin{bmatrix}\n",
    "1 &  \\dots & 1\\\\\\\n",
    "x_1 & \\dots & x_n \\\\\\\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "c+mx_1 \\\\\\\n",
    "c+mx_2 \\\\\\\n",
    "\\vdots\\\\\\\n",
    "c+mx_n\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{X}^\\top \\mathbf{y} - \\mathbf{X}^\\top\\mathbf{X}\\mathbf{w} =\n",
    "\\begin{bmatrix}y_1+y_2+  \\dots \\ +y_n\\\\\n",
    "x_1y_1+x_2y_2+ \\dots +x_ny_n\\\\\\\n",
    "\\end{bmatrix} - \\begin{bmatrix}\n",
    "c+mx_1 + c+mx_2 +     \\ \\  \\ \\ \\ \\ \\dots \\ \\ \\ \\ \\ \\ \\ + c+mx_n\\\\\\\n",
    "x_1(c+mx_1) + x_2(c+mx_2) + \\dots + x_n(c+mx_n)\\\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{X}^\\top \\mathbf{y} - \\mathbf{X}^\\top\\mathbf{X}\\mathbf{w} =\n",
    "\\begin{bmatrix}y_1-(c+mx_1)+y_2-(c+mx_2)+  \\ \\ \\ \\ \\dots\\ \\ \\ \\ \\ \\ \\ \\ +y_n-(c+mx_n)\\\\\n",
    "x_1y_1-x_1(c+mx_1)+x_2y_2-x_2(c+mx_2)+ \\ \\dots \\ +x_ny_n-x_n(c+mx_n)\\\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Subsituting value of equation(3) in the equation(2).\n",
    "\n",
    "$$\n",
    "\\therefore  \\frac{\\text{d}}{\\text{d}\\mathbf{w}}E(\\mathbf{w}) = -2\\begin{bmatrix}y_1-(c+mx_1)+y_2-(c+mx_2)+  \\ \\ \\ \\ \\dots\\ \\ \\ \\ \\ \\ \\ \\ +y_n-(c+mx_n)\\\\\n",
    "x_1y_1-x_1(c+mx_1)+x_2y_2-x_2(c+mx_2)+ \\ \\dots \\ +x_ny_n-x_n(c+mx_n)\\\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "\\therefore  \\frac{\\text{d}E(\\mathbf{w})}{\\text{d}w} = \\begin{bmatrix}-\\sum_{i=1}^n 2(y_i-mx_i-c) \\\\\n",
    "-\\sum_{i=1}^n 2x_i(y_i-mx_i-c)\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\therefore  \\frac{\\text{d}E(\\mathbf{w})}{\\text{d}w} = \\begin{bmatrix}\\frac{\\text{d}E(c,m)}{\\text{d}c} \\\\\n",
    "\\frac{\\text{d}E(c,m)}{\\text{d}m}\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Equation for Global Optimum\n",
    "\n",
    "Once again, we need to find the minimum of our objective function. Using our likelihood for multiple input regression we can now minimize for our parameter vector $\\mathbf{w}$. Firstly, just as in the single input case, we seek stationary points by finding parameter vectors that solve for when the gradients are zero,\n",
    "$$\n",
    "\\mathbf{0}=- 2\\mathbf{X}^\\top \\mathbf{y} + 2\\mathbf{X}^\\top\\mathbf{X}\\mathbf{w},\n",
    "$$\n",
    "where $\\mathbf{0}$ is a *vector* of zeros. Rearranging this equation we find the solution to be\n",
    "$$\n",
    "\\mathbf{w} = \\left[\\mathbf{X}^\\top \\mathbf{X}\\right]^{-1} \\mathbf{X}^\\top \\mathbf{y}\n",
    "$$ \n",
    "where $\\mathbf{A}^{-1}$ denotes [*matrix inverse*](http://en.wikipedia.org/wiki/Invertible_matrix).\n",
    "\n",
    "### Solving the Multivariate System\n",
    "\n",
    "The solution for $\\mathbf{w}$ is given in terms of a matrix inverse, but computation of a matrix inverse requires, in itself, an algorithm to resolve it. You'll know this if you had to invert, by hand, a $3\\times 3$ matrix in high school. From a numerical stability perspective, it is also best not to compute the matrix inverse directly, but rather to ask the computer to *solve* the  system of linear equations given by\n",
    "$$\\mathbf{X}^\\top\\mathbf{X} \\mathbf{w} = \\mathbf{X}^\\top\\mathbf{y}$$\n",
    "for $\\mathbf{w}$. This can be done in `numpy` using the command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.solve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we can obtain the solution using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.linalg.solve(np.dot(X.T, X), np.dot(X.T, y))\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can map it back to the liner regression and plot the fit as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = w[1]; c=w[0]\n",
    "f_test = m*x_test + c\n",
    "print(m)\n",
    "print(c)\n",
    "plt.plot(x_test, f_test, 'b-')\n",
    "plt.plot(x, y, 'rx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Linear Regression\n",
    "\n",
    "A major advantage of the new system is that we can build a linear regression on a multivariate system. The matrix calculus didn't specify what the length of the vector $\\mathbf{x}$ should be, or equivalently the size of the design matrix. \n",
    "\n",
    "### Movie Body Count Data\n",
    "\n",
    "Let's load back in the movie body count data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pods.datasets.movie_body_count()\n",
    "movies = data['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remind ourselves of the features we've been provided with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(', '.join(movies.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will build a design matrix based on the numeric features: year, Body_Count, Length_Minutes in an effort to predict the rating. We build the design matrix as follows:\n",
    "\n",
    "## Relation to Single Input System\n",
    "\n",
    "Bias as an additional feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_features = ['Year', 'Body_Count', 'Length_Minutes']\n",
    "X = movies.loc[:, select_features]\n",
    "X['Eins'] = 1 # add a column for the offset\n",
    "y = movies[['IMDB_Rating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's perform a linear regression. But this time, we will create a pandas data frame for the result so we can store it in a form that we can visualise easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "w = pd.DataFrame(data=np.linalg.solve(np.dot(X.T, X), np.dot(X.T, y)),  # solve linear regression here\n",
    "                 index = X.columns,  # columns of X become rows of w\n",
    "                 columns=['regression_coefficient']) # the column of X is the value of regression coefficient\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the residuals to see how good our estimates are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y - np.dot(X, w)).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which shows our model *hasn't* yet done a great job of representation, because the spread of values is large. We can check what the rating is dominated by in terms of regression coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we have to be a little careful about interpretation because our input values live on different scales, however it looks like we are dominated by the bias, with a small negative effect for later films (but bear in mind the years are large, so this effect is probably larger than it looks) and a positive effect for length. So it looks like long earlier films generally do better, but the residuals are so high that we probably haven't modelled the system very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('ui-uNlFHoms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('78YNphT90-k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution with QR Decomposition\n",
    "\n",
    "Performing a solve instead of a matrix inverse is the more numerically stable approach, but we can do even better. A [QR-decomposition](http://en.wikipedia.org/wiki/QR_decomposition) of a matrix factorises it into a matrix which is an orthogonal matrix $\\mathbf{Q}$, so that $\\mathbf{Q}^\\top \\mathbf{Q} = \\mathbf{I}$. And a matrix which is upper triangular, $\\mathbf{R}$. \n",
    "$$\n",
    "\\mathbf{X}^\\top \\mathbf{X} \\boldsymbol{\\beta} = \\mathbf{X}^\\top \\mathbf{y}\n",
    "$$\n",
    "$$\n",
    "(\\mathbf{Q}\\mathbf{R})^\\top (\\mathbf{Q}\\mathbf{R})\\boldsymbol{\\beta} = (\\mathbf{Q}\\mathbf{R})^\\top \\mathbf{y}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{R}^\\top (\\mathbf{Q}^\\top \\mathbf{Q}) \\mathbf{R} \\boldsymbol{\\beta} = \\mathbf{R}^\\top \\mathbf{Q}^\\top \\mathbf{y}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{R}^\\top \\mathbf{R} \\boldsymbol{\\beta} = \\mathbf{R}^\\top \\mathbf{Q}^\\top \\mathbf{y}\n",
    "$$\n",
    "$$\n",
    "\\mathbf{R} \\boldsymbol{\\beta} = \\mathbf{Q}^\\top \\mathbf{y}\n",
    "$$\n",
    "This is a more numerically stable solution because it removes the need to compute $\\mathbf{X}^\\top\\mathbf{X}$ as an intermediate. Computing $\\mathbf{X}^\\top\\mathbf{X}$ is a bad idea because it involves squaring all the elements of $\\mathbf{X}$ and thereby potentially reducing the numerical precision with which we can represent the solution. Operating on $\\mathbf{X}$ directly preserves the numerical precision of the model.\n",
    "\n",
    "This can be more particularly seen when we begin to work with *basis functions* in the next week. Some systems that can be resolved with the QR decomposition can not be resolved by using solve directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "Q, R = np.linalg.qr(X)\n",
    "w = sp.linalg.solve_triangular(R, np.dot(Q.T, y)) \n",
    "w = pd.DataFrame(w, index=X.columns)\n",
    "w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
